{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_Customer_Reviews_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13C_HUP_Th7q"
      },
      "source": [
        "#**Project Overview:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EscV2gopTdEm"
      },
      "source": [
        "In this project I will analyze data from the Amazon Web Service.\n",
        "More specifically, I will work with the Amazon Customer Reviews Data set. This data set has many categories. Each of the categories has its own data which contains columns such as marketplace, customer_id,product_title,product title, star_rating and more. \n",
        "I will print out some data frames so you will be able to see.\n",
        "\n",
        "This project could be split into 4 parts as follows:\n",
        "* Connecting to Amazon and getting the data.\n",
        "* Preprocessing the data and doing some feature engineering\n",
        "* fitting some classification models to the data sets\n",
        "* Using mini-batches for Machine Learning\n",
        "\n",
        "If you want to read more about the data set you can do so [here](https://s3.amazonaws.com/amazon-reviews-pds/readme.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4QJ10tWVxVd"
      },
      "source": [
        "Libraries and modules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZHxzBVoV13z",
        "outputId": "a86d9c8c-49e9-41c7-c7d6-2f166a3f670f"
      },
      "source": [
        "# More about boto3 can be read here https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\n",
        "%pip install boto3\n",
        "!pip3 install flair\n",
        "\n",
        "import boto3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import math\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "classifier = TextClassifier.load('sentiment-fast') # building sentiment features\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.18.53-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.53\n",
            "  Downloading botocore-1.21.53-py3-none-any.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 42.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.53->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.53->boto3) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.53 botocore-1.21.53 jmespath-0.10.0 s3transfer-0.5.0 urllib3-1.26.7\n",
            "Collecting flair\n",
            "  Downloading flair-0.9-py3-none-any.whl (319 kB)\n",
            "\u001b[K     |████████████████████████████████| 319 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.11.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 38.1 MB/s \n",
            "\u001b[?25hCollecting more-itertools~=8.8.0\n",
            "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 66.5 MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.62.3)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.9.0+cu102)\n",
            "Collecting conllu>=4.0\n",
            "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 56.3 MB/s \n",
            "\u001b[?25hCollecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.19.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.6.3)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 743 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 36.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: gdown, mpld3, overrides, segtok, sqlitedict, ftfy, langdetect, wikipedia-api\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9704 sha256=d38079b851d6d2c7af8e1bc5d6afd9669df0cab8038e614529c96697f0fc9fbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=817fbd698db594cd4c50fb79fd48e3606905dd8524e36b4fc92b3feb6af731c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10186 sha256=f4d59c8cbd52f07c00c543fc65f3827dace2449d1bdb4ff0f8783e467ac1dcba\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=747eb84b8cb44fcbb394a362e19261b2de539e1a3fff447c0d5c65e7f938d46a\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=488342525941506cd6210f7ae53c6d9b8fa94e605b96ff6a319c44df73b00a0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=883f49e02763c67fae4bf82e2584a92bb32911d235c0f05a2781e28fc3e496b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=997a8c478dc4c85aa0f29b872eeaf3b5cabebca809dbe51bbcc5d26e79b4d34a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13475 sha256=1ffa41c47ae9cbdf38063671eb8675e658a284c622f90e00603254249b6034e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built gdown mpld3 overrides segtok sqlitedict ftfy langdetect wikipedia-api\n",
            "Installing collected packages: requests, importlib-metadata, tokenizers, sentencepiece, sacremoses, pyyaml, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, mpld3, more-itertools, langdetect, konoha, janome, gdown, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.1\n",
            "    Uninstalling importlib-metadata-4.8.1:\n",
            "      Successfully uninstalled importlib-metadata-4.8.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 8.10.0\n",
            "    Uninstalling more-itertools-8.10.0:\n",
            "      Successfully uninstalled more-itertools-8.10.0\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.9 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.17 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 pyyaml-5.4.1 requests-2.26.0 sacremoses-0.0.46 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 transformers-4.11.2 wikipedia-api-0.5.4\n",
            "2021-10-04 11:03:41,663 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-fasttext-rnn/sentiment-en-mix-ft-rnn_v8.pt not found in cache, downloading to /tmp/tmpsawe033s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1241977025/1241977025 [00:53<00:00, 23317102.86B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-04 11:04:35,334 copying /tmp/tmpsawe033s to cache at /root/.flair/models/sentiment-en-mix-ft-rnn_v8.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-04 11:04:39,665 removing temp file /tmp/tmpsawe033s\n",
            "2021-10-04 11:04:39,840 loading file /root/.flair/models/sentiment-en-mix-ft-rnn_v8.pt\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-tLghSdWkcr"
      },
      "source": [
        "#**Chapter 1: Connecting to Amazon:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iNPAXsuXDIL"
      },
      "source": [
        "In this chapter I will connect to the Amazon Cloud Storage using boto3. Using boto3, I will be able to connect to the amazon-reviews-pds bucket.\n",
        "I'll create a connection to the bucket using the resource method of boto3. \n",
        "The Amazon_product_reviews variable will connect to the Amazon product reviews dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bsVThSbYrRa",
        "outputId": "491344ee-ff60-4d54-ef54-50f6869f4120"
      },
      "source": [
        " \n",
        "# declaring a connection to AWSS3\n",
        "s3conn = boto3.resource('s3',\n",
        "                        aws_access_key_id ='HIDDEN_FOR_SAFETY'  ,\n",
        "                        aws_secret_access_key = 'HIDDEN_FOR_SAFETY')\n",
        "Amazon_product_reviews = s3conn.Bucket('amazon-reviews-pds')  # Connect to a database of Amazon product reviews\n",
        "print(Amazon_product_reviews)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s3.Bucket(name='amazon-reviews-pds')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S237qYmibDYV"
      },
      "source": [
        "Let's do this:\n",
        "* Focus only on data from the tab separated values (tsv) folder.\n",
        "  * to do that, we will get all the keys of the files and keep them in a list, along with their size in bytes.\n",
        "  * Then, we will go over the list of keys and keep only the keys which include tsv objects containing reviews from the United States\n",
        "* Print out the elements of the said list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdjil59wbBgr"
      },
      "source": [
        "To reiterate: I will loop over the keys_list and check for each item i in the list if it is both of the type tsv and is from the US. Each key that matches both conditions, will be saved into a filtered list. Finally, I will print the first 10 elements of the filtered keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDiKe_zwfl3H",
        "outputId": "6e322cfd-58fb-49af-8faf-da224b2ee0ad"
      },
      "source": [
        "keys_list = []\n",
        "for my_bucket_object in Amazon_product_reviews.objects.all():\n",
        "    keys_list.append([my_bucket_object.key,my_bucket_object.size])\n",
        "filtered_list=[]\n",
        "size=0\n",
        "for i in range(len(keys_list)):\n",
        "  if ('tsv' in (keys_list[i][0].lower()) and 'reviews_us' in (keys_list[i][0]).lower()):\n",
        "    filtered_list.append([keys_list[i][0],keys_list[i][1]])\n",
        "filtered_list[:]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['tsv/amazon_reviews_us_Apparel_v1_00.tsv.gz', 648641286],\n",
              " ['tsv/amazon_reviews_us_Automotive_v1_00.tsv.gz', 582145299],\n",
              " ['tsv/amazon_reviews_us_Baby_v1_00.tsv.gz', 357392893],\n",
              " ['tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz', 914070021],\n",
              " ['tsv/amazon_reviews_us_Books_v1_00.tsv.gz', 2740337188],\n",
              " ['tsv/amazon_reviews_us_Books_v1_01.tsv.gz', 2692708591],\n",
              " ['tsv/amazon_reviews_us_Books_v1_02.tsv.gz', 1329539135],\n",
              " ['tsv/amazon_reviews_us_Camera_v1_00.tsv.gz', 442653086],\n",
              " ['tsv/amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv.gz', 2689739299],\n",
              " ['tsv/amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz', 1294879074],\n",
              " ['tsv/amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv.gz', 253570168],\n",
              " ['tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz', 18997559],\n",
              " ['tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz', 506979922],\n",
              " ['tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz', 27442648],\n",
              " ['tsv/amazon_reviews_us_Electronics_v1_00.tsv.gz', 698828243],\n",
              " ['tsv/amazon_reviews_us_Furniture_v1_00.tsv.gz', 148982796],\n",
              " ['tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz', 12134676],\n",
              " ['tsv/amazon_reviews_us_Grocery_v1_00.tsv.gz', 401337166],\n",
              " ['tsv/amazon_reviews_us_Health_Personal_Care_v1_00.tsv.gz', 1011180212],\n",
              " ['tsv/amazon_reviews_us_Home_Entertainment_v1_00.tsv.gz', 193168458],\n",
              " ['tsv/amazon_reviews_us_Home_Improvement_v1_00.tsv.gz', 503339178],\n",
              " ['tsv/amazon_reviews_us_Home_v1_00.tsv.gz', 1081002012],\n",
              " ['tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz', 247022254],\n",
              " ['tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz', 930744854],\n",
              " ['tsv/amazon_reviews_us_Lawn_and_Garden_v1_00.tsv.gz', 486772662],\n",
              " ['tsv/amazon_reviews_us_Luggage_v1_00.tsv.gz', 60320191],\n",
              " ['tsv/amazon_reviews_us_Major_Appliances_v1_00.tsv.gz', 24359816],\n",
              " ['tsv/amazon_reviews_us_Mobile_Apps_v1_00.tsv.gz', 557959415],\n",
              " ['tsv/amazon_reviews_us_Mobile_Electronics_v1_00.tsv.gz', 22870508],\n",
              " ['tsv/amazon_reviews_us_Music_v1_00.tsv.gz', 1521994296],\n",
              " ['tsv/amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz', 193389086],\n",
              " ['tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz', 512323500],\n",
              " ['tsv/amazon_reviews_us_Outdoors_v1_00.tsv.gz', 448963100],\n",
              " ['tsv/amazon_reviews_us_PC_v1_00.tsv.gz', 1512903923],\n",
              " ['tsv/amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv.gz', 17634794],\n",
              " ['tsv/amazon_reviews_us_Pet_Products_v1_00.tsv.gz', 515815253],\n",
              " ['tsv/amazon_reviews_us_Shoes_v1_00.tsv.gz', 642255314],\n",
              " ['tsv/amazon_reviews_us_Software_v1_00.tsv.gz', 94010685],\n",
              " ['tsv/amazon_reviews_us_Sports_v1_00.tsv.gz', 872478735],\n",
              " ['tsv/amazon_reviews_us_Tools_v1_00.tsv.gz', 333782939],\n",
              " ['tsv/amazon_reviews_us_Toys_v1_00.tsv.gz', 838451398],\n",
              " ['tsv/amazon_reviews_us_Video_DVD_v1_00.tsv.gz', 1512355451],\n",
              " ['tsv/amazon_reviews_us_Video_Games_v1_00.tsv.gz', 475199894],\n",
              " ['tsv/amazon_reviews_us_Video_v1_00.tsv.gz', 138929896],\n",
              " ['tsv/amazon_reviews_us_Watches_v1_00.tsv.gz', 162973819],\n",
              " ['tsv/amazon_reviews_us_Wireless_v1_00.tsv.gz', 1704713674]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2UMNYZ1f6KT"
      },
      "source": [
        "We Can see multiple datasets with different categories and different sizes in bytes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtBpSl0xgMy2"
      },
      "source": [
        "Since our resources are finite(Using google colab locally), I will want to do some analysis on a small dataset. let's find something which is relatively small. According to a quick calculation, Digital_Video_games seems to be about small enough. Let's download it. and do the following:\n",
        "* read the entire data from the Digital_video_games category into a pandas dataframe and call it *df*\n",
        "* print the number of datapoints and features.\n",
        "* we can calculate the average size of each data point(row)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEJrmiSZjUca"
      },
      "source": [
        "More Specifically: I will download the Digital_Video_Games data set, then go over it row by row, and trim it so it will be readable in the pandas data frame. Note that I have 2 replace methods for very close strings, for example \"b'\" and 'b\"'. this will get rid of the appropriate substring that I do not want in the final data frame. The replace method will only replace if it finds the substring. Additionally, when creating the data frame, I found out the rows 44914,118318 and 133454 ended up not being equal to 15 after the trimming, hence the if statement (I will remove them from the final data frame)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpxhEOq0jmB4",
        "outputId": "fb779656-e690-445c-cc6e-e136647afef8"
      },
      "source": [
        "keys_list=filtered_list[:]\n",
        "print('file to read/stream: ', keys_list[13][0]) # downloading: Digital_Video_Games==13, aka row 13 in filtered_list above.\n",
        "# changing the 13 to something else will download a different data set. from filtered_list above. see output in previous code block\n",
        "fileToStream = keys_list[13][0]\n",
        "s3conn.Bucket('amazon-reviews-pds').download_file(fileToStream, 'tmp.gz')\n",
        "% ls /content/ -lah\n",
        "\n",
        "with gzip.open('/content/tmp.gz', 'rb') as f_in:\n",
        "    tmp = f_in.readlines() # Reading lines into a python object\n",
        "### importing sys to calculate the size of each row in bytes.\n",
        "import sys\n",
        "totalsize=0\n",
        "temp=tmp\n",
        "final_data=[]\n",
        "for row in range(len(temp)):\n",
        "  curr_row=str(temp[row])\n",
        "  trimmed_row=curr_row.strip().split(\"\\\\t\")\n",
        "  trimmed_row[0]=trimmed_row[0].replace(\"b'\",'')\n",
        "  trimmed_row[0]=trimmed_row[0].replace('b\"','')\n",
        "  trimmed_row[-1]=trimmed_row[-1].replace('\\\\n\"','')\n",
        "  trimmed_row[-1]=trimmed_row[-1].replace(\"\\\\n'\",'')\n",
        "  if (len(trimmed_row)==15):\n",
        "    final_data.append(trimmed_row)\n",
        "    #getting the size of each row for the average\n",
        "    totalsize=totalsize+sys.getsizeof(trimmed_row)\n",
        "\n",
        "print(\"========================================================================\")\n",
        "df=pd.DataFrame(data=final_data[1:],columns=final_data[0])\n",
        "print(\"The Number of rows is \",len(df) , \" and The number of Columns is \",len(df.columns))\n",
        "avgsize=totalsize/len(df)\n",
        "print(\"The Average size in bytes for each data point is \", round(avgsize,3))\n",
        "print(\"========================================================================\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n",
            "total 27M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:04 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  27M Oct  4 11:04 tmp.gz\n",
            "========================================================================\n",
            "The Number of rows is  145428  and The number of Columns is  15\n",
            "The Average size in bytes for each data point is  232.002\n",
            "========================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2SUDx0Lkzna"
      },
      "source": [
        "Let's see what the data frame looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "nUJogCBhk3me",
        "outputId": "cdd603bd-bd75-4393-8ab5-f2041819720d"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>21269168</td>\n",
              "      <td>RSH1OZ87OYK92</td>\n",
              "      <td>B013PURRZW</td>\n",
              "      <td>603406193</td>\n",
              "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>A slight improvement from last year.</td>\n",
              "      <td>I keep buying madden every year hoping they ge...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>133437</td>\n",
              "      <td>R1WFOQ3N9BO65I</td>\n",
              "      <td>B00F4CEHNK</td>\n",
              "      <td>341969535</td>\n",
              "      <td>Xbox Live Gift Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011</td>\n",
              "      <td>R3YOOS71KM5M9</td>\n",
              "      <td>B00DNHLFQA</td>\n",
              "      <td>951665344</td>\n",
              "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hail to the great Yuri!</td>\n",
              "      <td>If you are prepping for the end of the world t...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>113118</td>\n",
              "      <td>R3R14UATT3OUFU</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>RV2W9SGDNQA2C</td>\n",
              "      <td>B00G9BNLQE</td>\n",
              "      <td>640460561</td>\n",
              "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>R3CFKLIZ0I2KOB</td>\n",
              "      <td>B00IMIL498</td>\n",
              "      <td>621922192</td>\n",
              "      <td>Double Dragon: Neon [Online Game Code]</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>US</td>\n",
              "      <td>38426028</td>\n",
              "      <td>R1LRYU1V0T3O38</td>\n",
              "      <td>B00S00IJH8</td>\n",
              "      <td>215163395</td>\n",
              "      <td>Sims 4</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>i like the new skills like herbalism in this</td>\n",
              "      <td>i like the new skills like herbalism in this, ...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>US</td>\n",
              "      <td>6057518</td>\n",
              "      <td>R44QKV6FE5CJ2</td>\n",
              "      <td>B004RMK4BC</td>\n",
              "      <td>384246568</td>\n",
              "      <td>Playstation Network Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Super</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>US</td>\n",
              "      <td>20715661</td>\n",
              "      <td>R2TX1KLPXXXNYS</td>\n",
              "      <td>B00K59HKIQ</td>\n",
              "      <td>384246568</td>\n",
              "      <td>Playstation Network Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Easy &amp; Fast</td>\n",
              "      <td>Excellent, fast and secure!!!</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>US</td>\n",
              "      <td>26540306</td>\n",
              "      <td>R1JEEW4C6R89BA</td>\n",
              "      <td>B00K59HKIQ</td>\n",
              "      <td>384246568</td>\n",
              "      <td>Playstation Network Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Ok</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace  ... review_date\n",
              "0          US  ...  2015-08-31\n",
              "1          US  ...  2015-08-31\n",
              "2          US  ...  2015-08-31\n",
              "3          US  ...  2015-08-31\n",
              "4          US  ...  2015-08-31\n",
              "5          US  ...  2015-08-31\n",
              "6          US  ...  2015-08-31\n",
              "7          US  ...  2015-08-31\n",
              "8          US  ...  2015-08-31\n",
              "9          US  ...  2015-08-31\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx7ryokLlN0K"
      },
      "source": [
        "#**Chapter 2:Preprocessing & Feature Engineering:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz8hkCnglV2M"
      },
      "source": [
        "In this chapter I will turn the text data into features that will help with making predictions. I will also do some additional tinkering with the data and preprocess it so it could be fed into the classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIPoF8oWl2Uu"
      },
      "source": [
        "Let's create a function,call it nlp_proc, which will do the following:\n",
        "* create a column called reviews_processed, which will be hold the review_body strings from the above dataframe *df*, all in lower-case. The next transformations will be done on the newly created reviews_processed column.\n",
        "* use the word_tokenize method to split the strings into words and keep only the alpha numerical values.\n",
        "* Remove redundancies\n",
        "* Removing junk words\n",
        "* rejoin the words back into a single string\n",
        "* Remove datapoints which ended up being empty strings after this whole process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8G4BEg1my_r"
      },
      "source": [
        "def nlp_proc(dataF):\n",
        "  #br is not a word, its a line break tag leftover from the trimming, \n",
        "  useless='br'\n",
        "  dataF['reviews_processed']=dataF['review_body'].str.lower()\n",
        "  engstop=stopwords.words('english')\n",
        "  for i in range(len(dataF)):\n",
        "    tokenized=word_tokenize(dataF['reviews_processed'][i])\n",
        "    alphatokenized=[]\n",
        "    for token in range(len(tokenized)):\n",
        "      if (tokenized[token].isalpha()):\n",
        "        alphatokenized.append(tokenized[token])\n",
        "    lmtzr=WordNetLemmatizer()\n",
        "    lemmatizedlist=[]\n",
        "    for alpha in range(len(alphatokenized)):\n",
        "      if (lmtzr.lemmatize(alphatokenized[alpha]) not in lemmatizedlist):\n",
        "        lemmatizedlist.append(lmtzr.lemmatize(alphatokenized[alpha]))\n",
        "    ## removing non informative words\n",
        "### stopwords are in engstop\n",
        "    informwords=[]\n",
        "    for wrd in lemmatizedlist:\n",
        "      if wrd not in engstop:\n",
        "        informwords.append(wrd)\n",
        "    ## remivoving line break tag leftover from the trimming so far.\n",
        "    if useless in informwords: informwords.remove(useless)\n",
        "    ### back to string\n",
        "    temp_string=' '.join([str(item) for item in informwords])\n",
        "    dataF['reviews_processed'][i]=temp_string\n",
        "### turning empty strings into NA's recognized by pandas.\n",
        "  ### I made sure the following code does exactly as asked in 7.\n",
        "  ### reviews_processed will have empty string if the review_body had an empty string\n",
        "  #### id's of empty strings in review_body\n",
        "  #RKHI9WDB7S5WR\n",
        "  #R2UJ6J6TUON90A\n",
        "  dataF['reviews_processed'].replace('', np.nan, inplace=True)\n",
        "  dataF.dropna(subset=['reviews_processed'], inplace=True)\n",
        "  ### reindexing the data frame so we can iterate over it more easily.\n",
        "  dataF.reset_index(drop=True, inplace=True)\n",
        "  return dataF"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcMocd38m8g1"
      },
      "source": [
        "This will take a while..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVfsuIlRm6h9"
      },
      "source": [
        "df=nlp_proc(df)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_l1ANngp_JC"
      },
      "source": [
        "Let's see the fruits of our labor..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Egi1FO9qC6o",
        "outputId": "8a250986-274f-481e-a5ce-32fbac29d4e6"
      },
      "source": [
        "df.reviews_processed.head(20)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     keep buying madden every year hoping get back ...\n",
              "1                                               awesome\n",
              "2     prepping end world one thing installed pc hail...\n",
              "3                                               perfect\n",
              "4                                               awesome\n",
              "5                                               awesome\n",
              "6     like new skill herbalism camping fun also buil...\n",
              "7                                                 super\n",
              "8                                 excellent fast secure\n",
              "9                                                    ok\n",
              "10    ha written many others quickly lost interest g...\n",
              "11    probably best game learning aspect real estate...\n",
              "12                                              awesome\n",
              "13                                 cool lages alot time\n",
              "14                      lame purchase almost never made\n",
              "15                                                great\n",
              "16                                              awesome\n",
              "17    pretty good first brink consciousness game dor...\n",
              "18                                        say xbox live\n",
              "19    fast receive ofc trustworthy safe place buy us...\n",
              "Name: reviews_processed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLv2N8kAqFRu"
      },
      "source": [
        "Now that we \"trimmed\" the strings, we want to get some Sentiment analysis on them, to see if theyre either positive or negative, using the flair library.\n",
        "Let's use a pretrained model to predict if the sentences are positive or negative I will use the pretrained model on the first 20 reviews in df.reviews_processed to see if we can get a feel / agree with the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GukdjopPx6rm",
        "outputId": "8d927104-a451-434b-dad9-c772b970dd50"
      },
      "source": [
        "classifier = TextClassifier.load('sentiment-fast')\n",
        "for sentiment in range(20):\n",
        "  ### processing...\n",
        "  sentence = Sentence(df.reviews_processed[sentiment])\n",
        "  classifier.predict(sentence)\n",
        "  print(\"The Sentiment is : \", sentence.labels[0].value,\" ==== The Score is \", round(sentence.labels[0].score,5), \" =====  The Review is  \",df.reviews_processed[sentiment])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-04 11:14:24,040 loading file /root/.flair/models/sentiment-en-mix-ft-rnn_v8.pt\n",
            "The Sentiment is :  NEGATIVE  ==== The Score is  0.99993  =====  The Review is   keep buying madden every year hoping get back football version little better last saying game look great thing wrong animation way player always tripping gameplay still slowed bloated control used take two button giant pita done opponent snap ball play clock run turbo movement slow awkward liked guessing like chance anything training online crossing finger rest one recommend buy bundle come download hate trading gamestop\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99709  =====  The Review is   awesome\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.85165  =====  The Review is   prepping end world one thing installed pc hail great yuri\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99409  =====  The Review is   perfect\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99709  =====  The Review is   awesome\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99709  =====  The Review is   awesome\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.97093  =====  The Review is   like new skill herbalism camping fun also build mode item\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.95087  =====  The Review is   super\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99753  =====  The Review is   excellent fast secure\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.56396  =====  The Review is   ok\n",
            "The Sentiment is :  NEGATIVE  ==== The Score is  0.99488  =====  The Review is   ha written many others quickly lost interest game still playing civ love shame ready expanded version waited decade better wa evolution total rewrite good really hope come use starting point forget ever happened failing place market strategy involves building civilisation\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99843  =====  The Review is   probably best game learning aspect real estate available hipsoft really hit ball park one high educational value well entertaining term leading basic development even though several year old know availability downloads apps mean still must budding mogul tomorrow\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99709  =====  The Review is   awesome\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.9736  =====  The Review is   cool lages alot time\n",
            "The Sentiment is :  NEGATIVE  ==== The Score is  0.99918  =====  The Review is   lame purchase almost never made\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99223  =====  The Review is   great\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99709  =====  The Review is   awesome\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.98271  =====  The Review is   pretty good first brink consciousness game dorian gray\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.61781  =====  The Review is   say xbox live\n",
            "The Sentiment is :  POSITIVE  ==== The Score is  0.99636  =====  The Review is   fast receive ofc trustworthy safe place buy using credit card\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAV6Xm5ly6G_"
      },
      "source": [
        "I guess I can agree with the pretrained model's assessment. But when running the code, I noticed that it takes a pretty long time to run, let's see how long it takes for different numbers of data points...\n",
        "Let's calculate the time it takes to compute the sentiments of 20,50,100,1000 and 10000 data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOkI_lCFzHAc",
        "outputId": "d38feb09-48cb-4d33-81b1-0c3794944924"
      },
      "source": [
        "# creating a function that take a column of strings, and outputs it as a list of Sentence types.\n",
        "### example/reminder for me:\n",
        "### examplelist=Sentifier(df.reviews_processed[:10])\n",
        "def Sentifier(dfcol):\n",
        "  outlist=[]\n",
        "  for i in range(len(dfcol)):\n",
        "    outlist.append(Sentence(dfcol[i]))\n",
        "  return outlist\n",
        "\n",
        "#sentifying the datapoints first. this is to make the comparison more intuitive.\n",
        "sentified_datapoints=Sentifier(df.reviews_processed[:10000])\n",
        "### computing the time to compute the sentiments of 20,50,100,1000,10000 datapoints.\n",
        "### sentify before everything.\n",
        "import time\n",
        "timelist=[]\n",
        "sentimentlist=[20,50,100,1000,10000]\n",
        "for datapoints in range(len(sentimentlist)):\n",
        "  start_time=time.time()\n",
        "  for sentiment in range(sentimentlist[datapoints]):\n",
        "    sentence = sentified_datapoints[sentiment]\n",
        "    classifier.predict(sentence)\n",
        "  endtime=time.time()-start_time\n",
        "  timelist.append(endtime)\n",
        "\n",
        "print('SentimentList',sentimentlist,'      Time List: ',timelist)\n",
        "average_time_approx=(timelist[0]/sentimentlist[0]+timelist[1]/sentimentlist[1]+timelist[2]/sentimentlist[2])/3\n",
        "print('On average, the time per data point is about ' ,round(average_time_approx,4),' seconds. so it would take approximately',round(144991*round(average_time_approx,4),4),'seconds for the entire data set')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentList [20, 50, 100, 1000, 10000]       Time List:  [0.04247331619262695, 0.13058924674987793, 0.21476101875305176, 2.4110569953918457, 23.877010583877563]\n",
            "On average, the time per data point is about  0.0023  seconds. so it would take approximately 333.4793 seconds for the entire data set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H_k18Wg0Rsl"
      },
      "source": [
        "according to my naive estimation it would take a pretty long time for the entire data set. I think I will need to do some mini-batching to speed things up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN0jEwjG0j1X"
      },
      "source": [
        "Let's define a batch function that will create mini-batches from a given list.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvLwF78519EV"
      },
      "source": [
        "## iterlist must be a list. ex=[]\n",
        "### returns a list of lists, each sub-list has a batch.\n",
        "def batch(iterlist,mini_batch_size):\n",
        "  batch_list=[]\n",
        "  if mini_batch_size >= len(iterlist):\n",
        "    return iterlist\n",
        "  if (len(iterlist) % mini_batch_size )!=0:\n",
        "    batch_list.append(iterlist[:len(iterlist) % mini_batch_size])\n",
        "    iterlist=iterlist[len(iterlist) % mini_batch_size:]\n",
        "  while iterlist:\n",
        "    batch_list.append(iterlist[:mini_batch_size])\n",
        "    iterlist=iterlist[mini_batch_size:]\n",
        "  return batch_list"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGtqpB6B2B3e"
      },
      "source": [
        "Defining a get_sentiment function that will take a mini batch of the text data points and will output the predictions for the given minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygdWcWlH2dKt"
      },
      "source": [
        "def get_sentiment(sent_list):\n",
        "  sent_score=[]\n",
        "  sent_value=[]\n",
        "  for i in range(len(sent_list)):\n",
        "    ## each location i in sent_list is holding many elements of different texts, the size of the mini batch size\n",
        "    ### hence the predict is happening on a list and it predicts on a batch-sized prediction at once.\n",
        "    classifier.predict(sent_list[i],verbose=True)\n",
        "    ## saving the scores and values\n",
        "    for j in range(len(sent_list[i])):\n",
        "      sent_score.append(sent_list[i][j].labels[0].score)\n",
        "      sent_value.append(sent_list[i][j].labels[0].value)\n",
        "  return [sent_score,sent_value]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQxcxh972ss0"
      },
      "source": [
        "Now That I have the appropriate functions I will use ALL OF Them on 10000 data points. Then I will compare the time it took to process the sentiments with both batch and get_sentiment VS the naive approach.\n",
        "Note that to make it as fair as possible, and because the .predict method does messy things. I will in both cases, preprocess the data points with my Sentifier function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrKU6RSi3Cs6"
      },
      "source": [
        "### preproccessing before timing, to make it as fair as possible.\n",
        "total_batch=Sentifier(df.reviews_processed[:10000])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWkual0Z3E6L"
      },
      "source": [
        "Now I will use both functions created above on the total_batch data and see how much time it takes to predict.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycLqfYYz3KZn",
        "outputId": "58451eaa-58ef-4ea6-beea-a500ce7a0005"
      },
      "source": [
        "start_time=time.time()\n",
        "batched_data=batch(total_batch,128)\n",
        "sentiment_data=get_sentiment(batched_data)\n",
        "endtime=time.time()-start_time\n",
        "print(\"\\n \\n Using Both Batch() and get_sentiment() functions took \",endtime,\" Seconds\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00, 43.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 43.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 36.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 46.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \n",
            " Using Both Batch() and get_sentiment() functions took  12.280565977096558  Seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl2TyHX23Vnu"
      },
      "source": [
        "We can see that we basically shaved off some of  the runtime on 10000 datapoints by batching. By using batch() and get_sentiment() it took less time. By iterating, one-by-one it took more time. So i will use batching from now on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzulYJDz3rtg"
      },
      "source": [
        "Let's batch and get_sentiment over the whole data set, and add sentiment score and sentiment values to the original data frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPPuMGsr3xmH",
        "outputId": "f8b6919a-54ad-4925-c8e4-aadf863fe72c"
      },
      "source": [
        "complete_batch=Sentifier(df.reviews_processed)\n",
        "complete_batched=batch(complete_batch,128)\n",
        "sentiment_cols=get_sentiment(complete_batched)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 25.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 36.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 39.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 38.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 38.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 41.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 46.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 36.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 43.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 38.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 45.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 39.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 36.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.81it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 38.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 37.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.81it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.81it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.81it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  7.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  6.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  5.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  7.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  7.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.81it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kt1DVJsk37EJ",
        "outputId": "2ffee0a2-983a-43b8-dbbe-d863e60646d5"
      },
      "source": [
        "###adding the appropriate columns\n",
        "df['sent_score']=sentiment_cols[0]\n",
        "df['sent_value']=sentiment_cols[1]\n",
        "df.head(20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>reviews_processed</th>\n",
              "      <th>sent_score</th>\n",
              "      <th>sent_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>21269168</td>\n",
              "      <td>RSH1OZ87OYK92</td>\n",
              "      <td>B013PURRZW</td>\n",
              "      <td>603406193</td>\n",
              "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>A slight improvement from last year.</td>\n",
              "      <td>I keep buying madden every year hoping they ge...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>keep buying madden every year hoping get back ...</td>\n",
              "      <td>0.999926</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>133437</td>\n",
              "      <td>R1WFOQ3N9BO65I</td>\n",
              "      <td>B00F4CEHNK</td>\n",
              "      <td>341969535</td>\n",
              "      <td>Xbox Live Gift Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997095</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011</td>\n",
              "      <td>R3YOOS71KM5M9</td>\n",
              "      <td>B00DNHLFQA</td>\n",
              "      <td>951665344</td>\n",
              "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hail to the great Yuri!</td>\n",
              "      <td>If you are prepping for the end of the world t...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>prepping end world one thing installed pc hail...</td>\n",
              "      <td>0.851653</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>113118</td>\n",
              "      <td>R3R14UATT3OUFU</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>perfect</td>\n",
              "      <td>0.994086</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>RV2W9SGDNQA2C</td>\n",
              "      <td>B00G9BNLQE</td>\n",
              "      <td>640460561</td>\n",
              "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997095</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>R3CFKLIZ0I2KOB</td>\n",
              "      <td>B00IMIL498</td>\n",
              "      <td>621922192</td>\n",
              "      <td>Double Dragon: Neon [Online Game Code]</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997095</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>US</td>\n",
              "      <td>38426028</td>\n",
              "      <td>R1LRYU1V0T3O38</td>\n",
              "      <td>B00S00IJH8</td>\n",
              "      <td>215163395</td>\n",
              "      <td>Sims 4</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>i like the new skills like herbalism in this</td>\n",
              "      <td>i like the new skills like herbalism in this, ...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>like new skill herbalism camping fun also buil...</td>\n",
              "      <td>0.970928</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>US</td>\n",
              "      <td>6057518</td>\n",
              "      <td>R44QKV6FE5CJ2</td>\n",
              "      <td>B004RMK4BC</td>\n",
              "      <td>384246568</td>\n",
              "      <td>Playstation Network Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Super</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>super</td>\n",
              "      <td>0.950873</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>US</td>\n",
              "      <td>20715661</td>\n",
              "      <td>R2TX1KLPXXXNYS</td>\n",
              "      <td>B00K59HKIQ</td>\n",
              "      <td>384246568</td>\n",
              "      <td>Playstation Network Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Easy &amp; Fast</td>\n",
              "      <td>Excellent, fast and secure!!!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>excellent fast secure</td>\n",
              "      <td>0.997535</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>US</td>\n",
              "      <td>26540306</td>\n",
              "      <td>R1JEEW4C6R89BA</td>\n",
              "      <td>B00K59HKIQ</td>\n",
              "      <td>384246568</td>\n",
              "      <td>Playstation Network Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Ok</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>ok</td>\n",
              "      <td>0.563957</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>US</td>\n",
              "      <td>8926809</td>\n",
              "      <td>R3B3UHK1FO0ERS</td>\n",
              "      <td>B004774IPU</td>\n",
              "      <td>151985175</td>\n",
              "      <td>Sid Meier's Civilization V</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>I am still playing Civ 4 and love it. It's a s...</td>\n",
              "      <td>As has been written by so many others, I quick...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>ha written many others quickly lost interest g...</td>\n",
              "      <td>0.994880</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>US</td>\n",
              "      <td>31525534</td>\n",
              "      <td>R2GVSDHW513SS1</td>\n",
              "      <td>B002LIT9EC</td>\n",
              "      <td>695277014</td>\n",
              "      <td>Build-a-lot 4: Power Source [Download]</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Probably the best game for learning aspects of...</td>\n",
              "      <td>Probably the best game for learning aspects of...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>probably best game learning aspect real estate...</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>R1R1NT516PYT73</td>\n",
              "      <td>B008ALUBYQ</td>\n",
              "      <td>112160022</td>\n",
              "      <td>Borderlands 2</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997095</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>US</td>\n",
              "      <td>22977584</td>\n",
              "      <td>R3K624QDQKENN9</td>\n",
              "      <td>B010KYDNDG</td>\n",
              "      <td>835376637</td>\n",
              "      <td>Minecraft for PC/Mac [Online Game Code]</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>FUN</td>\n",
              "      <td>COOL BUT IT LAGES ALOT OF THE TIME</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>cool lages alot time</td>\n",
              "      <td>0.973602</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011</td>\n",
              "      <td>R1FOXH7PCJX3V</td>\n",
              "      <td>B008ALUBYQ</td>\n",
              "      <td>112160022</td>\n",
              "      <td>Borderlands 2</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>One Star</td>\n",
              "      <td>Lames purchase I almost never made...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>lame purchase almost never made</td>\n",
              "      <td>0.999180</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>US</td>\n",
              "      <td>2239522</td>\n",
              "      <td>RA1246M1OMDWC</td>\n",
              "      <td>B004RMK4P8</td>\n",
              "      <td>384246568</td>\n",
              "      <td>Playstation Network Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Great</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>great</td>\n",
              "      <td>0.992227</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>US</td>\n",
              "      <td>48805811</td>\n",
              "      <td>R2I9SXWB0PAEKQ</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!!!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997095</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>US</td>\n",
              "      <td>18646481</td>\n",
              "      <td>R3UGL544NA0G9C</td>\n",
              "      <td>B00BI16Z22</td>\n",
              "      <td>552981447</td>\n",
              "      <td>Brink of Consciousness: Lonely Hearts Murders ...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>worth playing</td>\n",
              "      <td>pretty good but not as good as the first Brink...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>pretty good first brink consciousness game dor...</td>\n",
              "      <td>0.982713</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>US</td>\n",
              "      <td>10310935</td>\n",
              "      <td>R1CBA4Y92GVAVM</td>\n",
              "      <td>B004VSTQ2A</td>\n",
              "      <td>232803743</td>\n",
              "      <td>Xbox Live Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>What can I say...xbox live!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>say xbox live</td>\n",
              "      <td>0.617814</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>US</td>\n",
              "      <td>5587610</td>\n",
              "      <td>R24NEKNR01VEHU</td>\n",
              "      <td>B00GAC1D2G</td>\n",
              "      <td>384246568</td>\n",
              "      <td>Playstation Network Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Just amazing</td>\n",
              "      <td>Very fast to receive, and ofc a trustworthy an...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>fast receive ofc trustworthy safe place buy us...</td>\n",
              "      <td>0.996360</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   marketplace customer_id  ... sent_score sent_value\n",
              "0           US    21269168  ...   0.999926   NEGATIVE\n",
              "1           US      133437  ...   0.997095   POSITIVE\n",
              "2           US    45765011  ...   0.851653   POSITIVE\n",
              "3           US      113118  ...   0.994086   POSITIVE\n",
              "4           US    22151364  ...   0.997095   POSITIVE\n",
              "5           US    22151364  ...   0.997095   POSITIVE\n",
              "6           US    38426028  ...   0.970928   POSITIVE\n",
              "7           US     6057518  ...   0.950873   POSITIVE\n",
              "8           US    20715661  ...   0.997535   POSITIVE\n",
              "9           US    26540306  ...   0.563957   POSITIVE\n",
              "10          US     8926809  ...   0.994880   NEGATIVE\n",
              "11          US    31525534  ...   0.998430   POSITIVE\n",
              "12          US    22151364  ...   0.997095   POSITIVE\n",
              "13          US    22977584  ...   0.973602   POSITIVE\n",
              "14          US    45765011  ...   0.999180   NEGATIVE\n",
              "15          US     2239522  ...   0.992227   POSITIVE\n",
              "16          US    48805811  ...   0.997095   POSITIVE\n",
              "17          US    18646481  ...   0.982713   POSITIVE\n",
              "18          US    10310935  ...   0.617814   POSITIVE\n",
              "19          US     5587610  ...   0.996360   POSITIVE\n",
              "\n",
              "[20 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujy1iLZp7BNQ"
      },
      "source": [
        "I want to do some Logistic Regression using this data. I will set the star ratings of 1,2 to be zero and star ratings of 4,5 to be one. Neutral ratings of 3 will be ignored. I will remove bad values such as nans and infinities. Additionally, I will make sure that every feature has the right \".astype()\" value. Let's define the function _modifix_ to do that and apply it to our data frame df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "FwK0OZlG7m9C",
        "outputId": "5ffcacf9-463c-4c92-8584-22736a31db7c"
      },
      "source": [
        "def modifix(pandata):\n",
        "  binstar=[]\n",
        "  bin_purch=[]\n",
        "  \n",
        "  pandata['marketplace']=pandata['marketplace'].astype(str)\n",
        "  pandata['customer_id']=pandata['customer_id'].astype(str)\n",
        "  pandata['review_id']=pandata['review_id'].astype(str)\n",
        "  pandata['product_id']=pandata['product_id'].astype(str)\n",
        "  pandata['product_parent']=pandata['product_parent'].astype(str)\n",
        "  pandata['product_title']=pandata['product_title'].astype(str)\n",
        "  pandata['product_category']=pandata['product_category'].astype(str)\n",
        "  pandata['star_rating']=pandata['star_rating'].astype(int)\n",
        "  pandata['helpful_votes']=pandata['helpful_votes'].astype(int)\n",
        "  pandata['total_votes']=pandata['total_votes'].astype(int)\n",
        "  pandata['vine']=pandata['vine'].astype(str)\n",
        "  pandata['verified_purchase']=pandata['verified_purchase'].astype(str)\n",
        "  \n",
        "  for purchase in range(len(pandata)):\n",
        "    if pandata.verified_purchase[purchase]=='Y':\n",
        "      bin_purch.append(1)\n",
        "    else:\n",
        "      bin_purch.append(0)\n",
        "  ### 1 verified, 0 not verified purchase.\n",
        "  pandata['binverified']=bin_purch\n",
        "  pandata['binverified']=pandata['binverified'].astype(int)\n",
        "  \n",
        "  pandata['review_headline']=pandata['review_headline'].astype(str)\n",
        "  pandata['review_body']=pandata['review_body'].astype(str)\n",
        "  pandata['review_date']=pandata['review_date'].astype(str)\n",
        "  pandata['reviews_processed']=pandata['reviews_processed'].astype(str)\n",
        "  pandata['sent_score']=pandata['sent_score'].astype(float)\n",
        "  pandata['sent_value']=pandata['sent_value'].astype(str)\n",
        "  # binary sentiments 0 for negative 1 for positive.\n",
        "  binsent=[]\n",
        "  for val in range(len(pandata)):\n",
        "    if pandata.sent_value[val]==\"NEGATIVE\":\n",
        "      binsent.append(0)\n",
        "    else:\n",
        "      binsent.append(1)\n",
        "  pandata['binsent']=binsent\n",
        "\n",
        "  ### LOW STAR 0 HIGH STAR 1\n",
        "  for rating in range(len(pandata)):\n",
        "    if pandata.star_rating[rating]==1 or pandata.star_rating[rating]==2:\n",
        "      binstar.append(0)\n",
        "    elif pandata.star_rating[rating]==4 or pandata.star_rating[rating]==5:\n",
        "      binstar.append(1)\n",
        "    else:\n",
        "      binstar.append(np.nan)\n",
        "\n",
        "  pandata['binstar']=binstar\n",
        "\n",
        "  ##pandata['helpful_percent']=pandata['helpful_votes']/pandata['total_votes']\n",
        "\n",
        "  ### getting rid of np.inf, -np.inf and np.nan.\n",
        "  pandata.replace([np.inf, -np.inf], np.nan)\n",
        "  pandata.dropna(inplace=True)\n",
        "  #can only do that after we drop the np.nans\n",
        "  pandata['binstar']=pandata['binstar'].astype(int)\n",
        "  pandata.reset_index(drop=True, inplace=True)\n",
        "  return pandata\n",
        "\n",
        "\n",
        "\n",
        "df=modifix(df)\n",
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>reviews_processed</th>\n",
              "      <th>sent_score</th>\n",
              "      <th>sent_value</th>\n",
              "      <th>binverified</th>\n",
              "      <th>binsent</th>\n",
              "      <th>binstar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>21269168</td>\n",
              "      <td>RSH1OZ87OYK92</td>\n",
              "      <td>B013PURRZW</td>\n",
              "      <td>603406193</td>\n",
              "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>A slight improvement from last year.</td>\n",
              "      <td>I keep buying madden every year hoping they ge...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>keep buying madden every year hoping get back ...</td>\n",
              "      <td>0.999926</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>133437</td>\n",
              "      <td>R1WFOQ3N9BO65I</td>\n",
              "      <td>B00F4CEHNK</td>\n",
              "      <td>341969535</td>\n",
              "      <td>Xbox Live Gift Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997095</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011</td>\n",
              "      <td>R3YOOS71KM5M9</td>\n",
              "      <td>B00DNHLFQA</td>\n",
              "      <td>951665344</td>\n",
              "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hail to the great Yuri!</td>\n",
              "      <td>If you are prepping for the end of the world t...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>prepping end world one thing installed pc hail...</td>\n",
              "      <td>0.851653</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>113118</td>\n",
              "      <td>R3R14UATT3OUFU</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>perfect</td>\n",
              "      <td>0.994086</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>RV2W9SGDNQA2C</td>\n",
              "      <td>B00G9BNLQE</td>\n",
              "      <td>640460561</td>\n",
              "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997095</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace customer_id       review_id  ... binverified binsent binstar\n",
              "0          US    21269168   RSH1OZ87OYK92  ...           0       0       0\n",
              "1          US      133437  R1WFOQ3N9BO65I  ...           1       1       1\n",
              "2          US    45765011   R3YOOS71KM5M9  ...           1       1       1\n",
              "3          US      113118  R3R14UATT3OUFU  ...           1       1       1\n",
              "4          US    22151364   RV2W9SGDNQA2C  ...           1       1       1\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIxIxC308E1K"
      },
      "source": [
        "Since im about to use logistic regression:\n",
        "Reminder: one of the assumption of logistic regression is that the feature columns are independent of eachother. Therefore, multicollinearity is obviously violating the assumption. \n",
        "I could get a model with high accuracy, but it would not be reliable on real world data. Notice the correlation between the two columns helpful_votes and total_votes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOSkff9J7rHm",
        "outputId": "056b2d71-a430-4c20-93e9-ff5c84eb5e6c"
      },
      "source": [
        "print(\"The Correlation between helpful_votes and total votes is \",round((df['helpful_votes'].astype(int)).corr((df['total_votes']).astype(int)),5))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Correlation between helpful_votes and total votes is  0.96537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn5wm8NX8fjE"
      },
      "source": [
        "I think that the best way to get rid of this problem is to only use the helpful votes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWvgKezV8jyR"
      },
      "source": [
        "Since Idk what's going on with the mapper, I'll let the mapper do it's thing on everything and I will hard-code the part for reviews_processed myself.\n",
        "Additionally, I will have the column names appropriate for the new columns for each word in 'words'. Additionally, I decided to use instead of sent_value, the binsent column I created, so we dont have to worry about \"NEGATIVE\" and \"POSITIVE\" strings and we have 1s and 0s. I also decided to use binverified column too. I think it makes sense to take into account if a review has been made by an actual customer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HSDGfaW8tWw",
        "outputId": "0d4508a0-4ed0-4f66-92c7-335d58f7f01c"
      },
      "source": [
        "#### since idk what'ss going on with the mapper, i'll let the mapper do it's thing on everything else, and i will Hard-code the reviews_processed part myself\n",
        "vectorizer=TfidfVectorizer(max_features=100)\n",
        "tfidf=vectorizer.fit_transform(df['reviews_processed'])\n",
        "## okay now I have it in the same format as the shit i need for the final_array\n",
        "tfidf=tfidf.toarray()\n",
        "### The top 100 words will be stored in 'words'\n",
        "words=vectorizer.get_feature_names()\n",
        "#### now tfidf is a nparray with .shape of (133373, 100) ill concatenate and im done.\n",
        "\n",
        "mapper = DataFrameMapper([\n",
        "     ('helpful_votes', None),\n",
        "     ('sent_score', None),\n",
        "     ('binsent',None),\n",
        "     ('binverified',None),\n",
        "\n",
        " ], df_out=False)\n",
        "mapper_fit = mapper.fit(df)\n",
        "final_df = mapper.transform(df) # a numpy array \n",
        "\n",
        "final_df=np.concatenate((final_df, tfidf), axis=1)\n",
        "final_df.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(133373, 104)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK-X76jm91jm"
      },
      "source": [
        "Now we can fit a Logistic Regression Model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va_BejFP9-wv"
      },
      "source": [
        "#**Chapter 3: Modeling and Predictions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6aw5ZJg-CiM"
      },
      "source": [
        "I want to predict the star rating binstar using the other features. I will create a train/test split of the final_df dataframe and have the target variable be binstar. But first, I would like to normalize the helpful votes, to make the logistic regression work better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb2a-EtWzAil"
      },
      "source": [
        "###Naive Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DACyZDQ7-T00"
      },
      "source": [
        "#sum(final_Df[:,0]<0)\n",
        "## since there are no negative helpful votes all we have to do is just divide by the max to scale \n",
        "#the idea is ---> final_df[:,0]=final_df[:,0] / final_df[:0].max()\n",
        "max_helpful_votes=final_df[:,0].max()\n",
        "for i in range(len(final_df[:,0])):\n",
        "  final_df[i,0]=final_df[i,0]/max_helpful_votes\n",
        "y=np.array(df['binstar'])\n",
        "x_train_q3,x_test_q3,y_train_q3,y_test_q3=train_test_split(final_df,y,test_size=0.2,random_state=42)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xVWwDVB-Z5u"
      },
      "source": [
        "Now let's fit a Logistic Regression Model to the training set and get the accuracies and errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewxqK4Mk-lDF",
        "outputId": "6a496fba-ec92-41cd-8cb1-6713a1413509"
      },
      "source": [
        "logistic_model=LogisticRegression()\n",
        "logistic_model.fit(x_train_q3,y_train_q3)\n",
        "logistic_model_preds=logistic_model.predict(x_test_q3)\n",
        "training_score=logistic_model.score(x_train_q3,y_train_q3)\n",
        "testing_score=logistic_model.score(x_test_q3,y_test_q3)\n",
        "print(\"The train model accuracy is: \",training_score,\"    The test model accuracy is:  \", testing_score)\n",
        "print(\"The train model error is: \",1-training_score,\"    The test model error is:  \", 1-testing_score)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train model accuracy is:  0.878263884983786     The test model accuracy is:   0.8797000937207122\n",
            "The train model error is:  0.12173611501621395     The test model error is:   0.12029990627928777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0PiRzU3xr84"
      },
      "source": [
        "### Can I get better accuracy than this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KnpFE-BxwrN"
      },
      "source": [
        "Let's create a voting system of 3 different ML algorithms to try and increase the accuracy.\n",
        "\n",
        "The voting system will consist of the following algorithms:\n",
        "\n",
        "\n",
        "* Logistic Regression.\n",
        "I will choose this algorithm as one of my \"voters\" because first of all, it was pretty much designed for classification especially [0,1]\n",
        "\n",
        "\n",
        "* On-Line SVM with Stochastic Gradient Descent\n",
        "this algorithm is simple and very efficient. Additionally it appears to be extremely useful with the data set has many samples. I'll use the hinge loss for SGDClassifier to get an online SVM classifier\n",
        "\n",
        "* Naive Bayes:\n",
        "I really like this algorithm, even though this is a weak learner. The good news about this classifier is that it is super fast O(nk), n=number of features, k=number of label classes\n",
        "\n",
        "\n",
        "\n",
        "I will use sklearn to fit the algorithms. And then I will do some coding for the voting mechanism. I will then calculate the accuracy. \n",
        "The already-split data is in x_train_q3,x_test_q3,y_train_q3,y_test_q3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2_LYqkFyNBj"
      },
      "source": [
        "## importing naive bayes\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C39HTRcpyPaC"
      },
      "source": [
        "Creating a voting model that will classify each sample by the majority vote. The function will return the predictions. as a list the length of input of test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HzxEmWtyR54"
      },
      "source": [
        "def voted_predictions(x_train,x_test,y_train,y_test):\n",
        "  ### declaring three vote models.\n",
        "  final_preds=[]\n",
        "  #logistic regression\n",
        "  lr=LogisticRegression()\n",
        "  lr.fit(x_train,y_train)\n",
        "  lr_prediction=lr.predict(x_test)\n",
        "  #on line support vector machine\n",
        "  on_line_svm=SGDClassifier(loss='hinge')\n",
        "  on_line_svm.fit(x_train,y_train)\n",
        "  on_line_svm_prediction=on_line_svm.predict(x_test)\n",
        "  #naive bayes\n",
        "  gauss=GaussianNB()\n",
        "  gauss.fit(x_train_q3,y_train_q3)\n",
        "  gauss_prediction=gauss.predict(x_test)\n",
        "\n",
        "  voters_predictions=gauss_prediction+on_line_svm_prediction+lr_prediction\n",
        "  for i in range(len(voters_predictions)):\n",
        "    if voters_predictions[i]>1:\n",
        "      final_preds.append(1)\n",
        "    else:\n",
        "      final_preds.append(0)\n",
        "\n",
        "  return final_preds\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYuym9QfyT7K"
      },
      "source": [
        "Now, Since i can't use the .score method, i will have to create a function that will calculate the accuracy. \n",
        "As we Know, accuracy is calculated as follows: \n",
        "\n",
        "\n",
        "Accuracy=(TP+TN)/(TP+TN+FP+FN)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJqYpKRlyYyW"
      },
      "source": [
        "def voted_accuracy(real_list,predicted_list):\n",
        "  tp=0\n",
        "  tn=0\n",
        "  fp=0\n",
        "  fn=0\n",
        "  for i in range(len(real_list)):\n",
        "    if predicted_list[i]==1 & real_list[i]==1:\n",
        "      tp=tp+1\n",
        "    elif predicted_list[i]==0 & real_list[i]==0:\n",
        "      tn=tn+1  \n",
        "    elif predicted_list[i]==1 & real_list[i]==0:\n",
        "      fp=fp+1\n",
        "    else:\n",
        "      fn=fn+1\n",
        "    accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
        "  return accuracy\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szMXPBhEycIr"
      },
      "source": [
        "My algorithm will consist of both voted_accuracy and the voted_predictions functions. Let's time them and see what we get:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuyjTNmkydrK",
        "outputId": "4d5a1024-63e6-43ee-d87a-f174dc812bac"
      },
      "source": [
        "start_time_vote=time.time()\n",
        "vote_winners=voted_predictions(x_train_q3,x_test_q3,y_train_q3,y_test_q3)\n",
        "accuracy_is=voted_accuracy(y_test_q3,vote_winners)\n",
        "endtime_vote=time.time()-start_time_vote\n",
        "\n",
        "print(\"The accuracy for my algorithm is: \",accuracy_is,\" and the runtime was: \",round(endtime_vote,4),\" Seconds.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for my algorithm is:  0.9355951265229616  and the runtime was:  4.8448  Seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79pkzL4ey2V8"
      },
      "source": [
        "Okay so I can get better accuracy if I were to use a voting system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEpxFZhzy7NA"
      },
      "source": [
        "###Back To logistic Regression:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgyAX4xe-0zn"
      },
      "source": [
        "Let's see the change in error with increase in sample size. Note: Im only using logistic regression from now untill the end of this chapter to do some analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "ZM1-2GCh-6R7",
        "outputId": "18db3bec-7eaf-4e26-a130-042f5798c5db"
      },
      "source": [
        "test_errors=[]\n",
        "train_errors=[]\n",
        "test_acc=[]\n",
        "train_acc=[]\n",
        "length_list = [ 10 * 2**j for j in range(0,14+1) ]\n",
        "if length_list[-1]>len(final_df):\n",
        "  length_list[-1]=len(final_df)\n",
        "\n",
        "comparison_model=LogisticRegression(random_state=42)\n",
        "\n",
        "for n in range(len(length_list)):\n",
        "  comparison_model=LogisticRegression()\n",
        "  temp_feature_size=final_df[:length_list[n],:]\n",
        "  temp_y=y[:length_list[n]]\n",
        "  x_train,x_test,y_train,y_test=train_test_split(temp_feature_size,temp_y,test_size=0.2,random_state=42)\n",
        "  comparison_model.fit(x_train,y_train)\n",
        "  \n",
        "  train_errors.append(1-comparison_model.score(x_train,y_train))\n",
        "  test_errors.append(1-comparison_model.score(x_test,y_test))\n",
        "  train_acc.append(comparison_model.score(x_train,y_train))\n",
        "  test_acc.append(comparison_model.score(x_test,y_test))\n",
        "\n",
        "plt.title(\"Change in error with increase in Sample Size\",size=17)\n",
        "plt.xlabel(\"Sample Size N\",size=12)\n",
        "plt.ylabel(\"Error\",size=12)\n",
        "plt.plot(length_list,test_errors)\n",
        "plt.plot(length_list,train_errors)\n",
        "plt.xscale('log')\n",
        "plt.legend(['Test Error','Train Error'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcd9f45f750>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkBL20-d-_V7"
      },
      "source": [
        "We can see an overall improvement in test error when increasing the sample size. We can also see that both the test and train error converge to around the same number about 0.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17d1dxYi_DWQ"
      },
      "source": [
        "Let's see the Change in Accuracy with Increase in Sample Size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "ykNg7I-g_Ilr",
        "outputId": "25956bed-794e-4a66-cfff-e508d53aeb91"
      },
      "source": [
        "plt.title(\"Change in Accuracy with increase in Sample Size\",size=17)\n",
        "plt.xlabel(\"Sample Size N\",size=12)\n",
        "plt.ylabel(\"Accuracy\",size=12)\n",
        "plt.plot(length_list,test_acc)\n",
        "plt.plot(length_list,train_acc)\n",
        "plt.xscale('log')\n",
        "plt.legend(['Test Accuracy','Train Accuracy'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcd9f01f350>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8ObxSjG_fZb"
      },
      "source": [
        "So far, We've only used a single dataset from the Amazon Reviews Dataset.\n",
        "What I would like to do is to use more categories from the Amazon Reviews Dataset.\n",
        "Specifically, I would like to see what would happen if I would create a combined model:\n",
        "Firstly, I will run 10 different Logistic Regression models on 10 different Amazon Reviews categories, and examine the accuracies.\n",
        "The combined model will be created by averaging these 10 Logisic Regression Models (both coeffs and intercepts). What would have higher accuracy? The combiend model which was created by averaging 10 different data categories? or the model that was fitted on its appropriate category alone by itself?\n",
        "Ill create two tables which will be used to compare the two ideas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW0phl1vDZid"
      },
      "source": [
        "let's pick some random categories from the filtered_list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNT7hyr3DBpL",
        "outputId": "d39817e6-6043-411b-9789-6ee657c15482"
      },
      "source": [
        "filtered_list[16],filtered_list[34],filtered_list[11],filtered_list[28],filtered_list[26],filtered_list[13],filtered_list[25],filtered_list[37],filtered_list[43],filtered_list[15]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz', 12134676],\n",
              " ['tsv/amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv.gz', 17634794],\n",
              " ['tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz', 18997559],\n",
              " ['tsv/amazon_reviews_us_Mobile_Electronics_v1_00.tsv.gz', 22870508],\n",
              " ['tsv/amazon_reviews_us_Major_Appliances_v1_00.tsv.gz', 24359816],\n",
              " ['tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz', 27442648],\n",
              " ['tsv/amazon_reviews_us_Luggage_v1_00.tsv.gz', 60320191],\n",
              " ['tsv/amazon_reviews_us_Software_v1_00.tsv.gz', 94010685],\n",
              " ['tsv/amazon_reviews_us_Video_v1_00.tsv.gz', 138929896],\n",
              " ['tsv/amazon_reviews_us_Furniture_v1_00.tsv.gz', 148982796])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhHCFBZyAChK"
      },
      "source": [
        "Let's try this with 10 categories:\n",
        "Gift_Card, Personal_Care_Appliances,Digital_Software\t,Mobile_Electronics,Major_Appliances,Digital_Video_Games,Luggage,Software,Video,Furniture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzgkLMagAk5K"
      },
      "source": [
        "Now I will do ALL of the preprocessing and feature engineering that I have done above on every category. I will try to make it clearer using functions, but this is gonna be kind of ugly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_uRssWnA6lH"
      },
      "source": [
        "## creating a function that will download the data, and turn it into a pandas data frame.\n",
        "### input will be the category index which is the category's filtered_list row index\n",
        "### second input is the number of rows for the OUTPUT DF! \n",
        "def download_and_pandatize(category_index,num_rows):\n",
        "  num_rows=num_rows+1\n",
        "  fileToStream = keys_list[category_index][0]\n",
        "  s3conn.Bucket('amazon-reviews-pds').download_file(fileToStream, 'tmp.gz')\n",
        "  % ls /content/ -lah\n",
        "  with gzip.open('/content/tmp.gz', 'rb') as f_in:\n",
        "    ### downloading 10001 rows because the first row is the column names!\n",
        "      downloaded_data = [next(f_in) for x in range(num_rows)] # Reading lines into a python object\n",
        "  data_set=[]\n",
        "  for row in range(len(downloaded_data)):\n",
        "    curr_row=str(downloaded_data[row])\n",
        "    trimmed_row=curr_row.strip().split(\"\\\\t\")\n",
        "    trimmed_row[0]=trimmed_row[0].replace(\"b'\",'')\n",
        "    trimmed_row[0]=trimmed_row[0].replace('b\"','')\n",
        "    trimmed_row[-1]=trimmed_row[-1].replace('\\\\n\"','')\n",
        "    trimmed_row[-1]=trimmed_row[-1].replace(\"\\\\n'\",'')\n",
        "    ### the if gets rid of outlier rows with problematic syntax.\n",
        "    if (len(trimmed_row)==15):\n",
        "      data_set.append(trimmed_row)\n",
        "  output_data=pd.DataFrame(data=data_set[1:],columns=data_set[0])\n",
        "  return output_data\n",
        "\n",
        "\n",
        "#### adding the sent_score and sent_value columns to the data frame, by function.\n",
        "### input should be the whole data frame.\n",
        "def sentiment_score_value_cols(df):\n",
        "  sentiments=get_sentiment(batch(Sentifier(df.reviews_processed),128))\n",
        "  df['sent_score']=sentiments[0]\n",
        "  df['sent_value']=sentiments[1]\n",
        "  return df\n",
        "\n",
        "\n",
        "def df_to_nparray(df):\n",
        "  vectorizer=TfidfVectorizer(max_features=100)\n",
        "  tfidf=vectorizer.fit_transform(df['reviews_processed']) \n",
        "  tfidf=tfidf.toarray()\n",
        "   \n",
        "  mapper = DataFrameMapper([\n",
        "      ('helpful_votes', None),\n",
        "      ('sent_score', None),\n",
        "      ('binsent',None),\n",
        "      ('binverified',None),\n",
        "\n",
        "  ], df_out=False)\n",
        "  mapper_fit = mapper.fit(df)\n",
        "  final_df = mapper.transform(df) # a numpy array \n",
        "  ### Reminder: first 4 cols will be from the DataFrameMapper and the last 100 will be from the tfidfe\n",
        "  final_df=np.concatenate((final_df, tfidf), axis=1)\n",
        "  return final_df \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ### X_vals and Y_vals must both be np arrays.\n",
        "def learn_LogisticRegression(X_vals,Y_vals):\n",
        "  #### accuracies[0]= train accuracy,  accuracies[1] = test accuracy\n",
        "  accuracies=[]\n",
        "\n",
        "  x_train,x_test,y_train,y_test=train_test_split(X_vals,Y_vals,test_size=0.2)\n",
        "  logistic_model=LogisticRegression()\n",
        "  logistic_model.fit(x_train,y_train)\n",
        "  training_score=logistic_model.score(x_train,y_train)\n",
        "  testing_score=logistic_model.score(x_test,y_test)\n",
        "  accuracies.append(training_score)\n",
        "  accuracies.append(testing_score)\n",
        "  return logistic_model,accuracies\n",
        "\n",
        "\n",
        "### normalizing the helpful votes function\n",
        "### gets an np array according to how I pre-made it and normalizes to appropriate column.\n",
        "def normalize_helpful_votes(final_df):\n",
        "  max_helpful_votes=final_df[:,0].max()\n",
        "  for i in range(len(final_df[:,0])):\n",
        "    final_df[i,0]=final_df[i,0]/max_helpful_votes\n",
        "  return final_df"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG7q0E1REGoS",
        "outputId": "fd3529d5-aee1-43e4-a440-5ac27973ca5b"
      },
      "source": [
        "### each of these is a pandas dataframe with 10000 rows. \n",
        "Gift_Card=download_and_pandatize(16,10000)\n",
        "Personal_Care_Appliances=download_and_pandatize(34,10000)\n",
        "Digital_Software=download_and_pandatize(11,10000)\n",
        "Mobile_Electronics=download_and_pandatize(28,10000)\n",
        "Major_Appliances=download_and_pandatize(26,10000)\n",
        "Luggage=download_and_pandatize(25,10000)\n",
        "Software=download_and_pandatize(37,10000)\n",
        "Video=download_and_pandatize(43,10000)\n",
        "Furniture=download_and_pandatize(15,10000)\n",
        "Digital_Video_Games=download_and_pandatize(13,10000)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  12M Oct  4 11:22 tmp.gz\n",
            "total 17M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  17M Oct  4 11:22 tmp.gz\n",
            "total 19M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  19M Oct  4 11:22 tmp.gz\n",
            "total 22M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  22M Oct  4 11:22 tmp.gz\n",
            "total 24M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  24M Oct  4 11:22 tmp.gz\n",
            "total 58M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  58M Oct  4 11:22 tmp.gz\n",
            "total 90M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  90M Oct  4 11:22 tmp.gz\n",
            "total 133M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 133M Oct  4 11:22 tmp.gz\n",
            "total 143M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 143M Oct  4 11:22 tmp.gz\n",
            "total 27M\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 11:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Oct  4 10:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Sep 30 17:11 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Sep 30 17:12 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  27M Oct  4 11:22 tmp.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Likrtvf1EK8z"
      },
      "source": [
        "### processing...\n",
        "Gift_Card=nlp_proc(Gift_Card)\n",
        "Personal_Care_Appliances=nlp_proc(Personal_Care_Appliances)\n",
        "Digital_Software=nlp_proc(Digital_Software)\n",
        "Mobile_Electronics=nlp_proc(Mobile_Electronics)\n",
        "Major_Appliances=nlp_proc(Major_Appliances)\n",
        "Luggage=nlp_proc(Luggage)\n",
        "Software=nlp_proc(Software)\n",
        "Video=nlp_proc(Video)\n",
        "Furniture=nlp_proc(Furniture)\n",
        "Digital_Video_Games=nlp_proc(Digital_Video_Games)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yStxXe5MEM-5",
        "outputId": "5ce39514-2532-4f9e-a927-e9df33820820"
      },
      "source": [
        "## adding sentiments score and value columns...\n",
        "Gift_Card=sentiment_score_value_cols(Gift_Card)\n",
        "Personal_Care_Appliances=sentiment_score_value_cols(Personal_Care_Appliances)\n",
        "Digital_Software=sentiment_score_value_cols(Digital_Software)\n",
        "Mobile_Electronics=sentiment_score_value_cols(Mobile_Electronics)\n",
        "Major_Appliances=sentiment_score_value_cols(Major_Appliances)\n",
        "Luggage=sentiment_score_value_cols(Luggage)\n",
        "Software=sentiment_score_value_cols(Software)\n",
        "Video=sentiment_score_value_cols(Video)\n",
        "Furniture=sentiment_score_value_cols(Furniture)\n",
        "Digital_Video_Games=sentiment_score_value_cols(Digital_Video_Games)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 40.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 46.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 54.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 52.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 44.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 46.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 49.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 56.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 46.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 53.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 62.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 48.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 55.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 55.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 49.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 47.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 50.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 60.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 55.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 49.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 52.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 51.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 43.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 47.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 53.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 50.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 50.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 51.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 49.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 56.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 41.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 49.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 51.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 54.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 44.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 56.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 47.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 48.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 59.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 59.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 64.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 51.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 50.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 51.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 41.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 45.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 55.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 49.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 52.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 47.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 42.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 54.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 46.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 51.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 41.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 53.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 54.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 44.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 44.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 58.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 59.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 55.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 48.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 48.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 48.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 48.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 59.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 43.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 46.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 43.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 48.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 61.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 40.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 49.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 53.81it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 35.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 36.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.81it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.55it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.81it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.19it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.81it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.28it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.51it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.10it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  6.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  8.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.23it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.92it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.91it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.08it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.86it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.75it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.29it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.35it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.33it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.46it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.27it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.44it/s]\n",
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 45.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.83it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.99it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.17it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.02it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 33.38it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.84it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.66it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.12it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 34.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.26it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.60it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.03it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.18it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.01it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.07it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 31.88it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.24it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.13it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 27.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNEbIs-tGPaa"
      },
      "source": [
        "### preparing the data frames for the DataFrameMapper and the tfidf vectorizer \n",
        "Gift_Card=modifix(Gift_Card)\n",
        "Personal_Care_Appliances=modifix(Personal_Care_Appliances)\n",
        "Digital_Software=modifix(Digital_Software)\n",
        "Mobile_Electronics=modifix(Mobile_Electronics)\n",
        "Major_Appliances=modifix(Major_Appliances)\n",
        "Luggage=modifix(Luggage)\n",
        "Software=modifix(Software)\n",
        "Video=modifix(Video)\n",
        "Furniture=modifix(Furniture)\n",
        "Digital_Video_Games=modifix(Digital_Video_Games)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M58R1tWRGTn7"
      },
      "source": [
        "### saving all the Y values\n",
        "Y_Gift_Card=Gift_Card['binstar']\n",
        "Y_Personal_Care_Appliances=Personal_Care_Appliances['binstar']\n",
        "Y_Digital_Software=Digital_Software['binstar']\n",
        "Y_Mobile_Electronics=Mobile_Electronics['binstar']\n",
        "Y_Major_Appliances=Major_Appliances['binstar']\n",
        "Y_Luggage=Luggage['binstar']\n",
        "Y_Software=Software['binstar']\n",
        "Y_Video=Video['binstar']\n",
        "Y_Furniture=Furniture['binstar']\n",
        "Y_Digital_Video_Games=Digital_Video_Games['binstar']"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R14oE5oSGWQn"
      },
      "source": [
        "Creating a function that will get a data frame as input, compute the tfidf vectorizer, then Use the dataframe mapper then output an np.array ready for regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMC-AuLFGX35"
      },
      "source": [
        "\n",
        "### turning every data frame into an nparray ready for the LogisticRegression.\n",
        "Gift_Card=df_to_nparray(Gift_Card)\n",
        "Personal_Care_Appliances=df_to_nparray(Personal_Care_Appliances)\n",
        "Digital_Software=df_to_nparray(Digital_Software)\n",
        "Mobile_Electronics=df_to_nparray(Mobile_Electronics)\n",
        "Major_Appliances=df_to_nparray(Major_Appliances)\n",
        "Luggage=df_to_nparray(Luggage)\n",
        "Software=df_to_nparray(Software)\n",
        "Video=df_to_nparray(Video)\n",
        "Furniture=df_to_nparray(Furniture)\n",
        "Digital_Video_Games=df_to_nparray(Digital_Video_Games)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgwfcZy-GaxD"
      },
      "source": [
        "### applying normalization to the  helpful votes column.\n",
        "\n",
        "Gift_Card=normalize_helpful_votes(Gift_Card)\n",
        "Personal_Care_Appliances=normalize_helpful_votes(Personal_Care_Appliances)\n",
        "Digital_Software=normalize_helpful_votes(Digital_Software)\n",
        "Mobile_Electronics=normalize_helpful_votes(Mobile_Electronics)\n",
        "Major_Appliances=normalize_helpful_votes(Major_Appliances)\n",
        "Luggage=normalize_helpful_votes(Luggage)\n",
        "Software=normalize_helpful_votes(Software)\n",
        "Video=normalize_helpful_votes(Video)\n",
        "Furniture=normalize_helpful_votes(Furniture)\n",
        "Digital_Video_Games=normalize_helpful_votes(Digital_Video_Games)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_2zSRilGfbB"
      },
      "source": [
        "Time For the Logistic Regression!\n",
        "learn_LogisticRegression is  a Function that takes the nparray and the y value and trains a logistic regression model, then returns it. This will help me save a few lines of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49n_yIMwGiQj"
      },
      "source": [
        "Gift_Card_Model,Gift_Card_Acc=learn_LogisticRegression(Gift_Card,Y_Gift_Card)\n",
        "Personal_Care_Appliances_Model,Personal_Care_Appliances_Acc=learn_LogisticRegression(Personal_Care_Appliances,Y_Personal_Care_Appliances)\n",
        "Digital_Software_Model,Digital_Software_Acc=learn_LogisticRegression(Digital_Software,Y_Digital_Software)\n",
        "Mobile_Electronics_Model,Mobile_Electronics_Acc=learn_LogisticRegression(Mobile_Electronics,Y_Mobile_Electronics)\n",
        "Major_Appliances_Model,Major_Appliances_Acc=learn_LogisticRegression(Major_Appliances,Y_Major_Appliances)\n",
        "Luggage_Model,Luggage_Acc=learn_LogisticRegression(Luggage,Y_Luggage)\n",
        "Software_Model,Software_Acc=learn_LogisticRegression(Software,Y_Software)\n",
        "Video_Model,Video_Acc=learn_LogisticRegression(Video,Y_Video)\n",
        "Furniture_Model,Furniture_Acc=learn_LogisticRegression(Furniture,Y_Furniture)\n",
        "Digital_Video_Games_Model,Digital_Video_Games_Acc=learn_LogisticRegression(Digital_Video_Games,Y_Digital_Video_Games)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-EXpKyNGm28"
      },
      "source": [
        "Accuracies_Table = pd.DataFrame(\n",
        "    {'Gift_Card': Gift_Card_Acc,\n",
        "     'Personal_Care_Appliances': Personal_Care_Appliances_Acc,\n",
        "     'Digital_Software': Digital_Software_Acc,\n",
        "     'Mobile_Electronics': Mobile_Electronics_Acc,\n",
        "     'Major_Appliances':Major_Appliances_Acc,\n",
        "     'Luggage':Luggage_Acc,\n",
        "     'Software':Software_Acc,\n",
        "     'Video':Video_Acc,\n",
        "     'Furniture':Furniture_Acc,\n",
        "     'Digital_Video_Games':Digital_Video_Games_Acc,\n",
        "    },\n",
        "    index=['Train_Accuracies', 'Test_Accuracies'])\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNqtzMi6HCXt"
      },
      "source": [
        "Averaging the fitted models coefficients and intercepts from all categories to create a combined model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVZM2ZWxHCK3"
      },
      "source": [
        "total_coeffs=Gift_Card_Model.coef_+Personal_Care_Appliances_Model.coef_+Digital_Software_Model.coef_+Mobile_Electronics_Model.coef_+Major_Appliances_Model.coef_+Luggage_Model.coef_+Software_Model.coef_+Video_Model.coef_+Furniture_Model.coef_+Digital_Video_Games_Model.coef_\n",
        "total_coeffs=total_coeffs/10\n",
        "total_intercepts=Gift_Card_Model.intercept_+Personal_Care_Appliances_Model.intercept_+Digital_Software_Model.intercept_+Mobile_Electronics_Model.intercept_+Major_Appliances_Model.intercept_+Luggage_Model.intercept_+Software_Model.intercept_+Video_Model.intercept_+Furniture_Model.intercept_+Digital_Video_Games_Model.intercept_\n",
        "total_intercepts_avg=total_intercepts/10\n",
        "combined_model=LogisticRegression()\n",
        "combined_model.coef_=total_coeffs\n",
        "combined_model.intercept_=total_intercepts_avg\n",
        "combined_model.classes_=np.array([0,1])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jbkNjJOHIf_"
      },
      "source": [
        "Testing the combined model on each category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I20-PRQHHJy"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(Gift_Card,Y_Gift_Card,test_size=0.2)\n",
        "Gift_Card_scores=[]\n",
        "Gift_Card_scores.append(combined_model.score(x_train,y_train))\n",
        "Gift_Card_scores.append(combined_model.score(x_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(Personal_Care_Appliances,Y_Personal_Care_Appliances,test_size=0.2)\n",
        "Personal_Care_Appliances_scores=[]\n",
        "Personal_Care_Appliances_scores.append(combined_model.score(x_train,y_train))\n",
        "Personal_Care_Appliances_scores.append(combined_model.score(x_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(Digital_Software,Y_Digital_Software,test_size=0.2)\n",
        "Digital_Software_scores=[]\n",
        "Digital_Software_scores.append(combined_model.score(x_train,y_train))\n",
        "Digital_Software_scores.append(combined_model.score(x_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(Mobile_Electronics,Y_Mobile_Electronics,test_size=0.2)\n",
        "Mobile_Electronics_scores=[]\n",
        "Mobile_Electronics_scores.append(combined_model.score(x_train,y_train))\n",
        "Mobile_Electronics_scores.append(combined_model.score(x_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(Major_Appliances,Y_Major_Appliances,test_size=0.2)\n",
        "Major_Appliances_scores=[]\n",
        "Major_Appliances_scores.append(combined_model.score(x_train,y_train))\n",
        "Major_Appliances_scores.append(combined_model.score(x_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(Luggage,Y_Luggage,test_size=0.2)\n",
        "Luggage_scores=[]\n",
        "Luggage_scores.append(combined_model.score(x_train,y_train))\n",
        "Luggage_scores.append(combined_model.score(x_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(Software,Y_Software,test_size=0.2)\n",
        "Software_scores=[]\n",
        "Software_scores.append(combined_model.score(x_train,y_train))\n",
        "Software_scores.append(combined_model.score(x_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(Video,Y_Video,test_size=0.2)\n",
        "Video_scores=[]\n",
        "Video_scores.append(combined_model.score(x_train,y_train))\n",
        "Video_scores.append(combined_model.score(x_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(Furniture,Y_Furniture,test_size=0.2)\n",
        "Furniture_scores=[]\n",
        "Furniture_scores.append(combined_model.score(x_train,y_train))\n",
        "Furniture_scores.append(combined_model.score(x_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(Digital_Video_Games,Y_Digital_Video_Games,test_size=0.2)\n",
        "Digital_Video_Games_scores=[]\n",
        "Digital_Video_Games_scores.append(combined_model.score(x_train,y_train))\n",
        "Digital_Video_Games_scores.append(combined_model.score(x_test,y_test))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0eg1GAqHLRh"
      },
      "source": [
        "combined_model_Table = pd.DataFrame(\n",
        "    {'Gift_Card': Gift_Card_scores,\n",
        "     'Personal_Care_Appliances': Personal_Care_Appliances_scores,\n",
        "     'Digital_Software': Digital_Software_scores,\n",
        "     'Mobile_Electronics': Mobile_Electronics_scores,\n",
        "     'Major_Appliances':Major_Appliances_scores,\n",
        "     'Luggage':Luggage_scores,\n",
        "     'Software':Software_scores,\n",
        "     'Video':Video_scores,\n",
        "     'Furniture':Furniture_scores,\n",
        "     'Digital_Video_Games':Digital_Video_Games_scores,\n",
        "    },\n",
        "    index=['Train_Accuracies', 'Test_Accuracies'])\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMdJUNXeGpQe"
      },
      "source": [
        "Accuracies when running a logistic regression model on each category separately:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "ndrhZ0kqGqMl",
        "outputId": "f2bb55d1-3d50-46dc-f384-8e1fea150a2d"
      },
      "source": [
        "Accuracies_Table"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gift_Card</th>\n",
              "      <th>Personal_Care_Appliances</th>\n",
              "      <th>Digital_Software</th>\n",
              "      <th>Mobile_Electronics</th>\n",
              "      <th>Major_Appliances</th>\n",
              "      <th>Luggage</th>\n",
              "      <th>Software</th>\n",
              "      <th>Video</th>\n",
              "      <th>Furniture</th>\n",
              "      <th>Digital_Video_Games</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train_Accuracies</th>\n",
              "      <td>0.96573</td>\n",
              "      <td>0.920595</td>\n",
              "      <td>0.869333</td>\n",
              "      <td>0.890480</td>\n",
              "      <td>0.912594</td>\n",
              "      <td>0.945058</td>\n",
              "      <td>0.870893</td>\n",
              "      <td>0.943621</td>\n",
              "      <td>0.927148</td>\n",
              "      <td>0.896964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test_Accuracies</th>\n",
              "      <td>0.96136</td>\n",
              "      <td>0.914882</td>\n",
              "      <td>0.870756</td>\n",
              "      <td>0.885979</td>\n",
              "      <td>0.910849</td>\n",
              "      <td>0.933226</td>\n",
              "      <td>0.855969</td>\n",
              "      <td>0.942308</td>\n",
              "      <td>0.908191</td>\n",
              "      <td>0.904352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Gift_Card  ...  Digital_Video_Games\n",
              "Train_Accuracies    0.96573  ...             0.896964\n",
              "Test_Accuracies     0.96136  ...             0.904352\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLbARGx-HMrz"
      },
      "source": [
        "Accuracies for the Combined Model, for each category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "z21mAVevHNEt",
        "outputId": "5b87bb5f-f0a0-4a99-f83e-986a53a7b65e"
      },
      "source": [
        "combined_model_Table"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gift_Card</th>\n",
              "      <th>Personal_Care_Appliances</th>\n",
              "      <th>Digital_Software</th>\n",
              "      <th>Mobile_Electronics</th>\n",
              "      <th>Major_Appliances</th>\n",
              "      <th>Luggage</th>\n",
              "      <th>Software</th>\n",
              "      <th>Video</th>\n",
              "      <th>Furniture</th>\n",
              "      <th>Digital_Video_Games</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Train_Accuracies</th>\n",
              "      <td>0.955553</td>\n",
              "      <td>0.896893</td>\n",
              "      <td>0.745377</td>\n",
              "      <td>0.835243</td>\n",
              "      <td>0.824382</td>\n",
              "      <td>0.913816</td>\n",
              "      <td>0.799836</td>\n",
              "      <td>0.926787</td>\n",
              "      <td>0.892646</td>\n",
              "      <td>0.828318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test_Accuracies</th>\n",
              "      <td>0.954147</td>\n",
              "      <td>0.907388</td>\n",
              "      <td>0.722344</td>\n",
              "      <td>0.826514</td>\n",
              "      <td>0.824382</td>\n",
              "      <td>0.915455</td>\n",
              "      <td>0.803943</td>\n",
              "      <td>0.926282</td>\n",
              "      <td>0.904343</td>\n",
              "      <td>0.836110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Gift_Card  ...  Digital_Video_Games\n",
              "Train_Accuracies   0.955553  ...             0.828318\n",
              "Test_Accuracies    0.954147  ...             0.836110\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBGofp0cHXUE"
      },
      "source": [
        "The accuracies are worse for all categories, I think its because the words we get from the tfidfvectorizer are not the same for all sub models. I also think that there's probably a different \"review - culture\" for each type of data set. \n",
        "It is important to note that the accuracies are not that worse than each category fitted to itself. This might be useful if we want just one final model to make predictions for all the different data sets. if we dont mind having 10 different models, then I think it would be better to use each one of the ten for its specific category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeHlxQtPdGNi"
      },
      "source": [
        "#**Chapter4: Streaming & fitting using batches:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZByZMHkadQLp"
      },
      "source": [
        "So far I was able to create a prediction model using a small subset of the data,that is because there's a limit on google colab's resources(memory). I can get around this problem by using the stochastic gradient descent classifier to train a model on a subset (batch) per epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmU5V_PmfPUB"
      },
      "source": [
        "I will now use the same train/test split from chapter 3 to try out the partial fit method of the stochastic gradient descent classifier. I will also compute the AVG of the log loss, with the equations provided below, which were taken from wikipedia. For every partial fit I will calculate the avg. of the log loss for the given epoch, and save it into a list. Finally, I will plot the avg. log loss as a function of the epochs.\n",
        "The equations for the loss are as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu_4nH7FfuRn"
      },
      "source": [
        " \\begin{aligned}J(\\mathbf {w} )\\ =\\ {\\frac {1}{N}}\\sum _{n=1}^{N}H(p_{n},q_{n})\\ =\\ -{\\frac {1}{N}}\\sum _{n=1}^{N}\\ {\\bigg [}y_{n}\\log {\\hat {y}}_{n}+(1-y_{n})\\log(1-{\\hat {y}}_{n}){\\bigg ]}\\,,\\end{aligned}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTwDFq5-fwEd"
      },
      "source": [
        "Where y hat of n is defined as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d288hGsifyH4"
      },
      "source": [
        "\\begin{aligned} {\\hat {y}}_{n}\\equiv g(\\mathbf {w} \\cdot \\mathbf {x} _{n})=1/(1+e^{-\\mathbf {w} \\cdot \\mathbf {x} _{n}})\\end{aligned}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Mfq8wRgddtxT",
        "outputId": "af2bd469-ed0a-4e7c-e488-d957c2fb64c8"
      },
      "source": [
        "## random state for reproducibility:\n",
        "GSDlogred = SGDClassifier(loss='log',random_state=42)\n",
        "epoque=30\n",
        "timelist=[x for x in range(1,epoque+1)]\n",
        "logistic_loss_array=[]\n",
        "for epo in range(0,epoque):\n",
        "  GSDlogred.partial_fit(x_train_q3,y_train_q3,classes=np.array(y),)\n",
        "  f_of_x=np.sum(GSDlogred.coef_)\n",
        "  ### denominator and numerator of y hat.\n",
        "  denominator=1+math.e**(-f_of_x)\n",
        "  numerator=1\n",
        "  ### yhat:\n",
        "  estimate=numerator/denominator\n",
        "  ### the cross entroy loss function\n",
        "  current_loss=(-1/len(x_train_q3)) * np.sum((y_train_q3*math.log(estimate)+(1-y_train_q3)*math.log(1-estimate)))\n",
        "  logistic_loss_array.append(current_loss)\n",
        "#### plotting loss over epochs\n",
        "plt.title(\"Average Log-Loss Over Epochs\",size=17)\n",
        "plt.xlabel(\"Epoch\",size=12)\n",
        "plt.ylabel(\"Loss\",size=12)\n",
        "plt.plot(timelist,logistic_loss_array)\n",
        "plt.legend(['loss'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcd5dd01290>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4pu2ArTrV6i"
      },
      "source": [
        "we can see a convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI6IIFrJrZv_"
      },
      "source": [
        "Now let's see the train and test error of that classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMYi8-mQrcYf",
        "outputId": "6af1b608-be0f-428b-9c78-3eab43f7d650"
      },
      "source": [
        "foc_sgd_training=GSDlogred.score(x_train_q3,y_train_q3)\n",
        "foc_sgd_testing=GSDlogred.score(x_test_q3,y_test_q3)\n",
        "\n",
        "print(\"The final output classifier (training) error is: \",1-foc_sgd_training,\"    The final output classifier (testing) error is \", 1-foc_sgd_testing)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The final output classifier (training) error is:  0.12177360400382387     The final output classifier (testing) error is  0.12018744142455484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IohqPT6BrsIL"
      },
      "source": [
        "We can see that the errors are pretty similar to the Logisitc Regression above in chapter 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmDC5X7Qr03-"
      },
      "source": [
        "As you probably already know, Amazon is pretty popular for selling books. I will do the following analysis on the Books_00 category data set.\n",
        "Since it's too big for google colab, I will download batches of it and run partial_fit on said batch, and i will update the model batch by batch. I will calculate the test accuracy for every batch AND the average test accuracy for the batches so far up to the current epoch. Let's see what we get:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdzJb23atUmu",
        "outputId": "c7d055e1-e2a1-4385-f88e-9ca34c35ff8d"
      },
      "source": [
        "maxCount = 100\n",
        "batch_size = 100000 #bytes \n",
        "counter=1\n",
        "all_accuracies_list=[]\n",
        "avg_accuracies_list=[]\n",
        "### category=Books_00 aka index 4\n",
        "fileToStream = keys_list[4][0]\n",
        "obj = s3conn.Object('amazon-reviews-pds', fileToStream) \n",
        "\n",
        "\n",
        "### RE-INITIALIZING THE GSDlogred model.\n",
        "## 909656\n",
        "GSDlogred = SGDClassifier(loss='log',random_state=4526543)\n",
        "\n",
        "\n",
        "\n",
        "with gzip.GzipFile(fileobj=obj.get()[\"Body\"]) as gzipfile:\n",
        "    while counter <= maxCount:\n",
        "        batch_temp = [i.decode().replace('\"\"','\"').strip().split('\\t') for i in gzipfile.readlines(batch_size)]  \n",
        "        print(\"===========================================================================\")\n",
        "        if counter==1:\n",
        "          current_batch=pd.DataFrame(batch_temp)\n",
        "          current_batch = current_batch.iloc[1:]\n",
        "          current_batch.reset_index(drop=True, inplace=True)\n",
        "          ### if this is the top of the data frame, the first row is useless as it is the column names and not the actual data iself.\n",
        "          print(\"Batch NUMBER\", counter)\n",
        "          print(\"Current Batch ROWS :\",current_batch.shape[0])\n",
        "        ## changing column names\n",
        "        else:\n",
        "          current_batch=pd.DataFrame(batch_temp)\n",
        "          print(\"Batch NUMBER\", counter)\n",
        "          print(\"Current Batch ROWS :\",current_batch.shape[0])\n",
        "        current_batch.columns=df.columns[:15]\n",
        "\n",
        "        ### Preprocessing, ill keep it short \n",
        "        current_batch=modifix(sentiment_score_value_cols(nlp_proc(current_batch)))\n",
        "        Y_FOR_MODEL=current_batch['binstar']\n",
        "        X_FOR_MODEL=normalize_helpful_votes(df_to_nparray(current_batch))\n",
        "        x_train_GSD,x_test_GSD,y_train_GSD,y_test_GSD=train_test_split(X_FOR_MODEL,Y_FOR_MODEL,test_size=0.2,random_state=42456243)\n",
        "        GSDlogred.partial_fit(x_train_GSD,y_train_GSD,classes=np.array([0,1]))\n",
        "        current_accuracy=GSDlogred.score(x_test_GSD,y_test_GSD)\n",
        "        print(\"The Test Accuracy for batch number\", counter,\"is:\",current_accuracy)\n",
        "        all_accuracies_list.append(current_accuracy)\n",
        "        avg_accuracies_list.append(np.sum(all_accuracies_list)/counter)\n",
        "        print(\"The Average Test accuracy for the batches so far is \",np.sum(all_accuracies_list)/counter)\n",
        "        print(\"===========================================================================\")\n",
        "        counter+=1\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========================================================================\n",
            "Batch NUMBER 1\n",
            "Current Batch ROWS : 240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 1 is: 0.8666666666666667\n",
            "The Average Test accuracy for the batches so far is  0.8666666666666667\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 2\n",
            "Current Batch ROWS : 215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 22.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 2 is: 0.926829268292683\n",
            "The Average Test accuracy for the batches so far is  0.8967479674796748\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 3\n",
            "Current Batch ROWS : 186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 11.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 3 is: 0.7941176470588235\n",
            "The Average Test accuracy for the batches so far is  0.8625378606727243\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 4\n",
            "Current Batch ROWS : 167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 20.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 4 is: 0.8125\n",
            "The Average Test accuracy for the batches so far is  0.8500283955045432\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 5\n",
            "Current Batch ROWS : 183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 19.98it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 5 is: 0.9411764705882353\n",
            "The Average Test accuracy for the batches so far is  0.8682580105212816\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 6\n",
            "Current Batch ROWS : 184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 10.64it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 6 is: 0.9428571428571428\n",
            "The Average Test accuracy for the batches so far is  0.8806911992439251\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 7\n",
            "Current Batch ROWS : 211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 21.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 7 is: 0.925\n",
            "The Average Test accuracy for the batches so far is  0.8870210279233645\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 8\n",
            "Current Batch ROWS : 215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 17.36it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 8 is: 0.8780487804878049\n",
            "The Average Test accuracy for the batches so far is  0.8858994969939196\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 9\n",
            "Current Batch ROWS : 226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.89it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 9 is: 0.8604651162790697\n",
            "The Average Test accuracy for the batches so far is  0.8830734546922696\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 10\n",
            "Current Batch ROWS : 183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 11.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 10 is: 0.9411764705882353\n",
            "The Average Test accuracy for the batches so far is  0.8888837562818661\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 11\n",
            "Current Batch ROWS : 209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 17.58it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 11 is: 0.975\n",
            "The Average Test accuracy for the batches so far is  0.8967125057107874\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 12\n",
            "Current Batch ROWS : 220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 18.44it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 12 is: 0.8571428571428571\n",
            "The Average Test accuracy for the batches so far is  0.8934150349967932\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 13\n",
            "Current Batch ROWS : 207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 18.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 13 is: 1.0\n",
            "The Average Test accuracy for the batches so far is  0.9016138784585783\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 14\n",
            "Current Batch ROWS : 195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 22.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 14 is: 0.868421052631579\n",
            "The Average Test accuracy for the batches so far is  0.8992429623280784\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 15\n",
            "Current Batch ROWS : 232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.25it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 15 is: 0.9318181818181818\n",
            "The Average Test accuracy for the batches so far is  0.9014146436274186\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 16\n",
            "Current Batch ROWS : 182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 16.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 16 is: 0.8857142857142857\n",
            "The Average Test accuracy for the batches so far is  0.9004333712578478\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 17\n",
            "Current Batch ROWS : 210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 17.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 17 is: 0.95\n",
            "The Average Test accuracy for the batches so far is  0.9033490553015038\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 18\n",
            "Current Batch ROWS : 243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.77it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 18 is: 0.9347826086956522\n",
            "The Average Test accuracy for the batches so far is  0.905095363823401\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 19\n",
            "Current Batch ROWS : 212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 18.70it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 19 is: 0.975609756097561\n",
            "The Average Test accuracy for the batches so far is  0.9088066476273041\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 20\n",
            "Current Batch ROWS : 238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 20 is: 0.9555555555555556\n",
            "The Average Test accuracy for the batches so far is  0.9111440930237167\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 21\n",
            "Current Batch ROWS : 210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 25.72it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 21 is: 0.925\n",
            "The Average Test accuracy for the batches so far is  0.9118038981178255\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 22\n",
            "Current Batch ROWS : 165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 16.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 22 is: 0.967741935483871\n",
            "The Average Test accuracy for the batches so far is  0.9143465361799185\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 23\n",
            "Current Batch ROWS : 219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 26.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 23 is: 0.9285714285714286\n",
            "The Average Test accuracy for the batches so far is  0.914965009762158\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 24\n",
            "Current Batch ROWS : 237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.85it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 24 is: 0.9787234042553191\n",
            "The Average Test accuracy for the batches so far is  0.9176216095327064\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 25\n",
            "Current Batch ROWS : 165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 26.95it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 11.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 25 is: 0.9354838709677419\n",
            "The Average Test accuracy for the batches so far is  0.9183360999901078\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 26\n",
            "Current Batch ROWS : 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 23.71it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 26 is: 0.9459459459459459\n",
            "The Average Test accuracy for the batches so far is  0.9193980171422554\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 27\n",
            "Current Batch ROWS : 219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 18.69it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 27 is: 0.9761904761904762\n",
            "The Average Test accuracy for the batches so far is  0.9215014415514488\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 28\n",
            "Current Batch ROWS : 236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 28 is: 0.9318181818181818\n",
            "The Average Test accuracy for the batches so far is  0.921869896560975\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 29\n",
            "Current Batch ROWS : 175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 12.57it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 29 is: 0.9411764705882353\n",
            "The Average Test accuracy for the batches so far is  0.9225356404929494\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 30\n",
            "Current Batch ROWS : 212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 25.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 30 is: 0.925\n",
            "The Average Test accuracy for the batches so far is  0.9226177858098512\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 31\n",
            "Current Batch ROWS : 244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 31 is: 0.9318181818181818\n",
            "The Average Test accuracy for the batches so far is  0.9229145727778619\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 32\n",
            "Current Batch ROWS : 173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 13.00it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 32 is: 0.7878787878787878\n",
            "The Average Test accuracy for the batches so far is  0.9186947044997658\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 33\n",
            "Current Batch ROWS : 176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 24.22it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 33 is: 0.8484848484848485\n",
            "The Average Test accuracy for the batches so far is  0.9165671331053743\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 34\n",
            "Current Batch ROWS : 201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 22.52it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 10.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 34 is: 0.9473684210526315\n",
            "The Average Test accuracy for the batches so far is  0.9174730533391171\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 35\n",
            "Current Batch ROWS : 236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.32it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 35 is: 0.9090909090909091\n",
            "The Average Test accuracy for the batches so far is  0.9172335635034541\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 36\n",
            "Current Batch ROWS : 161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 36 is: 0.6\n",
            "The Average Test accuracy for the batches so far is  0.9084215200728026\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 37\n",
            "Current Batch ROWS : 218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 17.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 37 is: 1.0\n",
            "The Average Test accuracy for the batches so far is  0.910896614124889\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 38\n",
            "Current Batch ROWS : 205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 21.67it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 38 is: 0.9473684210526315\n",
            "The Average Test accuracy for the batches so far is  0.9118563985177243\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 39\n",
            "Current Batch ROWS : 267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00, 29.59it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 39 is: 0.94\n",
            "The Average Test accuracy for the batches so far is  0.9125780293249621\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 40\n",
            "Current Batch ROWS : 182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 10.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 40 is: 0.9142857142857143\n",
            "The Average Test accuracy for the batches so far is  0.912620721448981\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 41\n",
            "Current Batch ROWS : 152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00, 18.79it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00,  9.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 41 is: 0.9655172413793104\n",
            "The Average Test accuracy for the batches so far is  0.9139108804716719\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 42\n",
            "Current Batch ROWS : 231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 28.30it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 42 is: 0.7674418604651163\n",
            "The Average Test accuracy for the batches so far is  0.9104235228524683\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 43\n",
            "Current Batch ROWS : 194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 15.63it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 43 is: 0.9166666666666666\n",
            "The Average Test accuracy for the batches so far is  0.9105687122434961\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 44\n",
            "Current Batch ROWS : 225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 44 is: 0.9761904761904762\n",
            "The Average Test accuracy for the batches so far is  0.9120601159695638\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 45\n",
            "Current Batch ROWS : 235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 29.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 45 is: 0.8863636363636364\n",
            "The Average Test accuracy for the batches so far is  0.911489083089432\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 46\n",
            "Current Batch ROWS : 236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 32.90it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 46 is: 0.9545454545454546\n",
            "The Average Test accuracy for the batches so far is  0.9124250911645629\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 47\n",
            "Current Batch ROWS : 210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 19.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 47 is: 0.975\n",
            "The Average Test accuracy for the batches so far is  0.9137564722036148\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 48\n",
            "Current Batch ROWS : 215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 19.50it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 48 is: 1.0\n",
            "The Average Test accuracy for the batches so far is  0.9155532123660395\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 49\n",
            "Current Batch ROWS : 214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 18.34it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 49 is: 1.0\n",
            "The Average Test accuracy for the batches so far is  0.917276616195304\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 50\n",
            "Current Batch ROWS : 180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 11.09it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 50 is: 0.9722222222222222\n",
            "The Average Test accuracy for the batches so far is  0.9183755283158423\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 51\n",
            "Current Batch ROWS : 262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00, 50.42it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 51 is: 0.96\n",
            "The Average Test accuracy for the batches so far is  0.9191916944272964\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 52\n",
            "Current Batch ROWS : 194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 31.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 52 is: 0.972972972972973\n",
            "The Average Test accuracy for the batches so far is  0.9202259497839441\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 53\n",
            "Current Batch ROWS : 226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 53 is: 0.9555555555555556\n",
            "The Average Test accuracy for the batches so far is  0.9208925461192575\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 54\n",
            "Current Batch ROWS : 185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 11.49it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 54 is: 1.0\n",
            "The Average Test accuracy for the batches so far is  0.9223574989689008\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 55\n",
            "Current Batch ROWS : 185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 22.21it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 55 is: 0.9714285714285714\n",
            "The Average Test accuracy for the batches so far is  0.9232497002863493\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 56\n",
            "Current Batch ROWS : 143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 56 is: 0.8888888888888888\n",
            "The Average Test accuracy for the batches so far is  0.9226361143685377\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 57\n",
            "Current Batch ROWS : 188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 12.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 57 is: 1.0\n",
            "The Average Test accuracy for the batches so far is  0.9239933755199669\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 58\n",
            "Current Batch ROWS : 220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 22.40it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 58 is: 0.926829268292683\n",
            "The Average Test accuracy for the batches so far is  0.9240422702229447\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 59\n",
            "Current Batch ROWS : 195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 20.93it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 59 is: 0.918918918918919\n",
            "The Average Test accuracy for the batches so far is  0.9239554337601646\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 60\n",
            "Current Batch ROWS : 180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 20.04it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 60 is: 0.9117647058823529\n",
            "The Average Test accuracy for the batches so far is  0.9237522549622011\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 61\n",
            "Current Batch ROWS : 181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 20.82it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 61 is: 0.8823529411764706\n",
            "The Average Test accuracy for the batches so far is  0.9230735776870252\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 62\n",
            "Current Batch ROWS : 218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 16.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 62 is: 0.9069767441860465\n",
            "The Average Test accuracy for the batches so far is  0.9228139513402353\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 63\n",
            "Current Batch ROWS : 189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 21.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 12.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 63 is: 0.9166666666666666\n",
            "The Average Test accuracy for the batches so far is  0.9227163753930357\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 64\n",
            "Current Batch ROWS : 270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00, 35.97it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.31it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 64 is: 0.9607843137254902\n",
            "The Average Test accuracy for the batches so far is  0.9233111869294803\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 65\n",
            "Current Batch ROWS : 249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.05it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 65 is: 0.8958333333333334\n",
            "The Average Test accuracy for the batches so far is  0.9228884507203089\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 66\n",
            "Current Batch ROWS : 234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.62it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 66 is: 0.9090909090909091\n",
            "The Average Test accuracy for the batches so far is  0.9226793970592573\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 67\n",
            "Current Batch ROWS : 208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 15.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 67 is: 0.8974358974358975\n",
            "The Average Test accuracy for the batches so far is  0.9223026284081625\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 68\n",
            "Current Batch ROWS : 250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 26.87it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 68 is: 1.0\n",
            "The Average Test accuracy for the batches so far is  0.9234452368139248\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 69\n",
            "Current Batch ROWS : 210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 23.53it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 69 is: 0.9230769230769231\n",
            "The Average Test accuracy for the batches so far is  0.9234398989336783\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 70\n",
            "Current Batch ROWS : 179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 14.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 13.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 70 is: 0.8529411764705882\n",
            "The Average Test accuracy for the batches so far is  0.9224327743270627\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 71\n",
            "Current Batch ROWS : 214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 21.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 71 is: 0.925\n",
            "The Average Test accuracy for the batches so far is  0.9224689324351322\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 72\n",
            "Current Batch ROWS : 242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.94it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 72 is: 0.8888888888888888\n",
            "The Average Test accuracy for the batches so far is  0.9220025429414345\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 73\n",
            "Current Batch ROWS : 210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 23.37it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 73 is: 0.975\n",
            "The Average Test accuracy for the batches so far is  0.9227285355038806\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 74\n",
            "Current Batch ROWS : 193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 16.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 74 is: 0.8648648648648649\n",
            "The Average Test accuracy for the batches so far is  0.9219465940087588\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 75\n",
            "Current Batch ROWS : 209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 18.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 75 is: 0.9487179487179487\n",
            "The Average Test accuracy for the batches so far is  0.9223035454048812\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 76\n",
            "Current Batch ROWS : 258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00, 114.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 22.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 76 is: 0.9183673469387755\n",
            "The Average Test accuracy for the batches so far is  0.9222517533198009\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 77\n",
            "Current Batch ROWS : 187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 18.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 77 is: 0.9428571428571428\n",
            "The Average Test accuracy for the batches so far is  0.9225193557813248\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 78\n",
            "Current Batch ROWS : 196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 17.47it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 78 is: 0.8947368421052632\n",
            "The Average Test accuracy for the batches so far is  0.9221631697085547\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 79\n",
            "Current Batch ROWS : 201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 27.96it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 79 is: 0.9459459459459459\n",
            "The Average Test accuracy for the batches so far is  0.9224642175090281\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 80\n",
            "Current Batch ROWS : 195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 20.45it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 80 is: 0.8947368421052632\n",
            "The Average Test accuracy for the batches so far is  0.922117625316481\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 81\n",
            "Current Batch ROWS : 196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 22.11it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 14.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 81 is: 0.8947368421052632\n",
            "The Average Test accuracy for the batches so far is  0.9217795909558486\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 82\n",
            "Current Batch ROWS : 193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 17.43it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 82 is: 0.918918918918919\n",
            "The Average Test accuracy for the batches so far is  0.9217447047114958\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 83\n",
            "Current Batch ROWS : 176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 26.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 83 is: 0.8571428571428571\n",
            "The Average Test accuracy for the batches so far is  0.9209663691986207\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 84\n",
            "Current Batch ROWS : 224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 13.16it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 84 is: 0.9534883720930233\n",
            "The Average Test accuracy for the batches so far is  0.9213535358997446\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 85\n",
            "Current Batch ROWS : 210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 28.15it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 85 is: 1.0\n",
            "The Average Test accuracy for the batches so far is  0.922278788418571\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 86\n",
            "Current Batch ROWS : 218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 19.76it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 86 is: 0.85\n",
            "The Average Test accuracy for the batches so far is  0.9214383373904481\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 87\n",
            "Current Batch ROWS : 244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 24.54it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 19.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 87 is: 0.8636363636363636\n",
            "The Average Test accuracy for the batches so far is  0.9207739468875275\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 88\n",
            "Current Batch ROWS : 197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 20.73it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 88 is: 0.9473684210526315\n",
            "The Average Test accuracy for the batches so far is  0.921076156821222\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 89\n",
            "Current Batch ROWS : 179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 14.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 89 is: 0.9090909090909091\n",
            "The Average Test accuracy for the batches so far is  0.920941491116387\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 90\n",
            "Current Batch ROWS : 194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 22.20it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 90 is: 0.8918918918918919\n",
            "The Average Test accuracy for the batches so far is  0.9206187177916704\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 91\n",
            "Current Batch ROWS : 205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 15.68it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 18.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 91 is: 0.9743589743589743\n",
            "The Average Test accuracy for the batches so far is  0.9212092700616408\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 92\n",
            "Current Batch ROWS : 211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 18.56it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 92 is: 0.95\n",
            "The Average Test accuracy for the batches so far is  0.9215222127783621\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 93\n",
            "Current Batch ROWS : 229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 30.80it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 93 is: 0.9534883720930233\n",
            "The Average Test accuracy for the batches so far is  0.9218659349215305\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 94\n",
            "Current Batch ROWS : 204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 18.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 94 is: 0.9487179487179487\n",
            "The Average Test accuracy for the batches so far is  0.9221515946427689\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 95\n",
            "Current Batch ROWS : 220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 19.14it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 20.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 95 is: 0.926829268292683\n",
            "The Average Test accuracy for the batches so far is  0.9222008333127679\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 96\n",
            "Current Batch ROWS : 229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 23.61it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 96 is: 0.8809523809523809\n",
            "The Average Test accuracy for the batches so far is  0.9217711619340142\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 97\n",
            "Current Batch ROWS : 269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00, 49.65it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 21.06it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 25.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 97 is: 0.9215686274509803\n",
            "The Average Test accuracy for the batches so far is  0.921769073949653\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 98\n",
            "Current Batch ROWS : 196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 3: 100%|██████████| 3/3 [00:00<00:00, 20.78it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 16.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 98 is: 0.9736842105263158\n",
            "The Average Test accuracy for the batches so far is  0.9222988202412515\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 99\n",
            "Current Batch ROWS : 152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 15.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 99 is: 0.8620689655172413\n",
            "The Average Test accuracy for the batches so far is  0.9216904378703019\n",
            "===========================================================================\n",
            "===========================================================================\n",
            "Batch NUMBER 100\n",
            "Current Batch ROWS : 176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 2: 100%|██████████| 2/2 [00:00<00:00, 13.48it/s]\n",
            "Inferencing on batch 4: 100%|██████████| 4/4 [00:00<00:00, 17.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Test Accuracy for batch number 100 is: 0.8529411764705882\n",
            "The Average Test accuracy for the batches so far is  0.9210029452563049\n",
            "===========================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSa2kAEItxZe"
      },
      "source": [
        "By watching the output we can see that the accuracy for each batch is kind of fluctuating. On the other Hand,we can clearly see that the average is growing slowly but surely and then stabilizing. I think it's easier to understand the accuracies graphically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "fiqHh9Xztz6o",
        "outputId": "35b5bf47-2601-44b8-bfbd-c669b97768a3"
      },
      "source": [
        "graph1=plt\n",
        "graph1.title(\"Accuracy for Each Batch\")\n",
        "graph1.xlabel(\"Batch Number\",size=12)\n",
        "graph1.ylabel('Accuracy')\n",
        "#graph1.plot(range(1,101),all_accuracies_list,)\n",
        "graph1.plot(range(1,101),all_accuracies_list)\n",
        "graph1.plot(range(1,101),all_accuracies_list,'bo',alpha=0.5)\n",
        "graph1.show()\n",
        "\n",
        "graph2=plt\n",
        "graph2.title(\"Average Accuracy for CUMULATIVE Batches\")\n",
        "graph2.xlabel(\"Total Batches Learned\",size=12)\n",
        "graph2.ylabel('Average Accuracy')\n",
        "#graph1.plot(range(1,101),all_accuracies_list,)\n",
        "graph2.plot(range(1,101),avg_accuracies_list)\n",
        "graph2.ylim((np.min(avg_accuracies_list)-0.001),(np.max(avg_accuracies_list)+0.003))\n",
        "graph2.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo_PbJLDt921"
      },
      "source": [
        "We can see that Every batch by itself has a different accuracy, and it seems to be fluctuating. On the other hand, we can see that at the start, the average accuracy fluctuates alot, then it starts to slowly but surely grow, at around 33 batches learned it peaks then it goes down again... After about 60 batches learned, the average accuracy kinds of stabilizes. It seems to converge. We do see an improvement as we use more and more batches. and then it stabilizes.\n",
        "\n",
        "\n",
        "we actually DO see an improvement as we use more and more batches."
      ]
    }
  ]
}